{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D_type\n",
       "NU     536450\n",
       "IoT    345875\n",
       "CD      32007\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['D_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S_MAC', 'D_MAC', 'FPT', 'LPT', 'FD', 'FAMin', 'FAMean', 'FAMax',\n",
       "       'FAStd', 'FIMean', 'FIMin', 'FIMax', 'FIStd', 'DSCP_C', 'ECN_C',\n",
       "       'TPackets', 'TBytes', 'SBytes', 'DBytes', 'PLM', 'FI', 'FIAT', 'BIAT',\n",
       "       'ForwardPC', 'BackwardPC', 'FlowR', 'FlowStd', 'FlowV', 'FH_M', 'FAPS',\n",
       "       'BAPS', 'FBPP', 'FFD', 'Proto', 'SIP', 'DIP', 'SPort', 'DPort',\n",
       "       'SDuration', 'SPC', 'SBCount', 'BytesPS', 'PacketsPS', 'RTT', 'HL_Sum',\n",
       "       'HL_Mode', 'HL_mean', 'SYN_FC', 'FIN_FC', 'RST_FC', 'PSH_FC', 'TCP_HD',\n",
       "       'RCount', 'DACount', 'MPackets', 'FThroughput', 'BThroughput',\n",
       "       'FJitter', 'BJitter', 'FBurst', 'FEntropy', 'PIA_Var', 'PL', 'PEntropy',\n",
       "       'SIT', 'STT', 'FIPD_Var', 'BIPD_Var', 'TCPWS_Sum', 'TCPWS_Mean',\n",
       "       'TCPWS_Mode', 'HTTPRM_L', 'HTTPRM_UL', 'HTTP_SCL', 'HTTP_SCUL:',\n",
       "       'label', 'type', 'D_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### important features ####\n",
    "\n",
    "a=['FEntropy','RTT','FIN_FC','TCPWS_Mean','RCount','FIMin','TBytes'] #  Attack Classification Without Device Type, Acc% 99.943\n",
    "\n",
    "b=['FEntropy','RTT','TCPWS_Sum','FIN_FC','FlowStd','D_type']  # Attack Classification With Device Type, Acc% 99.996\n",
    "\n",
    "c=['RTT','PL','TCPWS_Sum','FIN_FC','PIA_Var','FAMin','FIMean','FIStd','TBytes','FD','PSH_FC','FIPD_Var','FAMax','TCPWS_Mean','FEntropy','PEntropy'] # Device Classification Device Type, Acc% 84.553\n",
    "\n",
    "d=['S_MAC','TCPWS_Sum', 'RTT', 'PIA_Var', 'FlowStd', 'FD', 'FIN_FC', 'RCount', 'PL', 'FAMax', 'TCPWS_Mean', 'PEntropy', 'FIPD_Var', 'FIStd', 'FIMean', 'FEntropy', 'FIMin', 'PSH_FC', 'TBytes', 'FAMin'] # require features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data['D_type']\n",
    "X=data[c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X:\n",
    "      if X[i].dtype == 'object':\n",
    "            print(i)\n",
    "# no categorical data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.25.2'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D_type\n",
       "NU     536450\n",
       "IoT    345875\n",
       "CD      32007\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func for missing values imputation, encoding, and normalization\n",
    "\n",
    "def encod(data):\n",
    "  from sklearn import preprocessing\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "  try:\n",
    "    n=data.shape[1]\n",
    "    for i in range(n):\n",
    "      if data.iloc[:,i].dtype == 'object':\n",
    "\n",
    "        data.iloc[:,i]= label_encoder.fit_transform(data.iloc[:,i])\n",
    "        unique_classes = label_encoder.classes_\n",
    "        print(\"Unique Classes:\", unique_classes)\n",
    "        print(\"Encoded Labels:\", data.iloc[:,i])\n",
    "    return data\n",
    "  except:\n",
    "    if data.dtype == 'object':\n",
    "      n=len(data)\n",
    "      data= label_encoder.fit_transform(data)\n",
    "    return data\n",
    "  \n",
    "\n",
    "\n",
    "def normalize_scale(X):\n",
    "  m= X.values #returns a numpy array\n",
    "  cols_name = X.columns\n",
    "  scaler = preprocessing.MinMaxScaler()\n",
    "  x_scaled = scaler.fit_transform(m)\n",
    "  #scaler.transform(X) for scaling using the previous weights\n",
    "  Scale_X = pd.DataFrame(x_scaled,columns = cols_name)\n",
    "  return Scale_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=encod(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_13812\\3036197768.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(Y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "D_type\n",
       "NU     536450\n",
       "IoT    345875\n",
       "CD      32007\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EY=encod(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_13812\\1294995040.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(EY)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    536450\n",
       "1    345875\n",
       "0     32007\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(EY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# joblib.dump(scaler, \"AttackDetection_scalerV2.pkl\")\n",
    "\n",
    "# scaler = joblib.load(\"scaler.pkl\")\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RTT</th>\n",
       "      <th>PL</th>\n",
       "      <th>TCPWS_Sum</th>\n",
       "      <th>FIN_FC</th>\n",
       "      <th>PIA_Var</th>\n",
       "      <th>FAMin</th>\n",
       "      <th>FIMean</th>\n",
       "      <th>FIStd</th>\n",
       "      <th>TBytes</th>\n",
       "      <th>FD</th>\n",
       "      <th>PSH_FC</th>\n",
       "      <th>FIPD_Var</th>\n",
       "      <th>FAMax</th>\n",
       "      <th>TCPWS_Mean</th>\n",
       "      <th>FEntropy</th>\n",
       "      <th>PEntropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.094291</td>\n",
       "      <td>0.995854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914327</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914328</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.094291</td>\n",
       "      <td>0.995312</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914329</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914330</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995312</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914331</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>914332 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RTT        PL  TCPWS_Sum  FIN_FC  PIA_Var     FAMin    FIMean  FIStd  \\\n",
       "0       0.0  0.000000   0.000000     0.0      0.0  0.053732  0.500227    0.0   \n",
       "1       0.0  0.000000   0.000000     0.0      0.0  0.053732  0.500227    0.0   \n",
       "2       0.0  0.000000   0.000287     0.0      0.0  0.053732  0.500227    0.0   \n",
       "3       0.0  0.000000   0.002295     0.0      0.0  0.053732  0.500227    0.0   \n",
       "4       0.0  0.000000   0.000287     0.0      0.0  0.053732  0.500227    0.0   \n",
       "...     ...       ...        ...     ...      ...       ...       ...    ...   \n",
       "914327  0.0  0.000000   0.000000     0.0      0.0  0.053732  0.500227    0.0   \n",
       "914328  0.0  0.000000   0.002295     0.0      0.0  0.053732  0.500227    0.0   \n",
       "914329  0.0  0.000000   0.000287     0.0      0.0  0.053732  0.500227    0.0   \n",
       "914330  0.0  0.000004   0.000000     0.0      0.0  0.053732  0.500227    0.0   \n",
       "914331  0.0  0.000000   0.000287     0.0      0.0  0.053732  0.500227    0.0   \n",
       "\n",
       "          TBytes   FD  PSH_FC  FIPD_Var     FAMax  TCPWS_Mean  FEntropy  \\\n",
       "0       0.000000  0.0     0.0       0.0  0.000638    0.000000  0.996710   \n",
       "1       0.000000  0.0     0.0       0.0  0.000638    0.000000  0.996710   \n",
       "2       0.000002  0.0     0.0       0.0  0.000638    0.011786  0.996205   \n",
       "3       0.000004  0.0     0.0       0.0  0.000638    0.094291  0.995854   \n",
       "4       0.000002  0.0     0.0       0.0  0.000638    0.011786  0.996205   \n",
       "...          ...  ...     ...       ...       ...         ...       ...   \n",
       "914327  0.000000  0.0     0.0       0.0  0.000638    0.000000  0.996710   \n",
       "914328  0.000007  0.0     0.0       0.0  0.000638    0.094291  0.995312   \n",
       "914329  0.000002  0.0     0.0       0.0  0.000638    0.011786  0.996205   \n",
       "914330  0.000007  0.0     0.0       0.0  0.000638    0.000000  0.995312   \n",
       "914331  0.000002  0.0     0.0       0.0  0.000638    0.011786  0.996205   \n",
       "\n",
       "        PEntropy  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "...          ...  \n",
       "914327       0.0  \n",
       "914328       0.0  \n",
       "914329       0.0  \n",
       "914330       0.0  \n",
       "914331       0.0  \n",
       "\n",
       "[914332 rows x 16 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99932\n",
      "Precision: 0.99932\n",
      "Recall: 0.99932\n",
      "F1-score: 0.99932\n",
      "MCC: 0.99613\n",
      "Average Prediction Time: 1328.2817 ms\n"
     ]
    }
   ],
   "source": [
    "# attack detection\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99995\n",
      "Precision: 0.99995\n",
      "Recall: 0.99995\n",
      "F1-score: 0.99995\n",
      "MCC: 0.99969\n",
      "Average Prediction Time: 1328.5244 ms\n"
     ]
    }
   ],
   "source": [
    "# attack detection + DT\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83731\n",
      "Precision: 0.86440\n",
      "Recall: 0.83731\n",
      "F1-score: 0.82668\n",
      "MCC: 0.69785\n",
      "Average Prediction Time: 1541.9309 ms\n"
     ]
    }
   ],
   "source": [
    "# Device ID\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)\n",
    "\n",
    "# ID_Features=['S_MAC',\n",
    "# 'D_MAC',\n",
    "# 'FPT',\n",
    "# 'LPT',\n",
    "# 'SIT',\n",
    "# 'STT',\n",
    "# 'SIP',\n",
    "# 'DIP',\n",
    "# 'SPort',\n",
    "# 'DPort',\n",
    "# 'label',\n",
    "# 'type']\n",
    "\n",
    "ID_Features=['S_MAC',\n",
    "'D_MAC',\n",
    "'FPT',\n",
    "'LPT',\n",
    "'SIT',\n",
    "'STT',\n",
    "'SIP',\n",
    "'DIP',\n",
    "'SPort',\n",
    "'DPort',\n",
    "'label',\n",
    "'type']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encod(data):\n",
    "  n=data.shape[1]\n",
    "  from sklearn import preprocessing\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "  for i in range(n):\n",
    "      if data.iloc[:,i].dtype == 'object':\n",
    "\n",
    "        data.iloc[:,i]= label_encoder.fit_transform(data.iloc[:,i])\n",
    "        unique_classes = label_encoder.classes_\n",
    "        print(\"Unique Classes:\", unique_classes)\n",
    "        print(\"Encoded Labels:\", data.iloc[:,i])\n",
    "  return data\n",
    "\n",
    "\n",
    "def normalize_scale(X):\n",
    "  m= X.values #returns a numpy array\n",
    "  cols_name = X.columns\n",
    "  scaler = preprocessing.MinMaxScaler()\n",
    "  x_scaled = scaler.fit_transform(m)\n",
    "  #scaler.transform(X) for scaling using the previous weights\n",
    "  Scale_X = pd.DataFrame(x_scaled,columns = cols_name)\n",
    "  return Scale_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_type\n"
     ]
    }
   ],
   "source": [
    "Y=data[ID_Features]\n",
    "X=data.drop(ID_Features,axis=1)\n",
    "\n",
    "for i in X:\n",
    "      if X[i].dtype == 'object':\n",
    "            print(i)\n",
    "\n",
    "\n",
    "\n",
    "# func for missing values imputation, encoding, and normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes: ['CD' 'IoT' 'NU']\n",
      "Encoded Labels: 0         2\n",
      "1         2\n",
      "2         2\n",
      "3         2\n",
      "4         1\n",
      "         ..\n",
      "914327    2\n",
      "914328    2\n",
      "914329    1\n",
      "914330    2\n",
      "914331    1\n",
      "Name: D_type, Length: 914332, dtype: object\n",
      "Unique Classes: ['02:3e:c2:98:b6:13' '02:47:6a:5a:03:6a' '02:74:55:c5:ea:d9'\n",
      " '06:1d:58:18:44:d2' '06:29:f9:52:5c:f4' '06:79:dd:3f:87:16'\n",
      " '0a:4d:2d:fb:69:52' '0a:73:ba:bb:45:43' '0a:74:47:e0:c9:03'\n",
      " '0a:7f:2a:8f:34:17' '0e:3f:d9:e6:6b:75' '12:2c:22:3f:8f:b7'\n",
      " '12:44:cd:3f:90:39' '12:de:67:be:0a:93' '16:8b:65:9b:f2:77'\n",
      " '1a:32:84:f9:d9:11' '1a:b5:24:b1:05:47' '1a:bf:56:94:b7:a2'\n",
      " '1a:ce:60:49:25:2c' '1a:d2:5e:86:d6:b1' '1e:46:fb:21:7d:ba'\n",
      " '1e:5a:47:93:77:3d' '1e:66:8b:37:9b:d5' '26:22:86:56:9e:59'\n",
      " '26:67:1b:cb:6e:47' '26:a5:06:6e:68:0a' '26:b4:4f:79:f8:41'\n",
      " '26:e7:03:03:d1:11' '2a:61:e1:68:04:45' '2a:6d:30:53:12:a1'\n",
      " '2a:ea:37:8d:de:39' '2e:29:60:92:9c:21' '36:3a:dc:ea:24:94'\n",
      " '36:6e:e9:ce:4c:a3' '36:f0:f2:07:c6:77' '3a:0e:4c:1c:c8:2f'\n",
      " '3a:75:f4:62:1a:b4' '3a:b8:6e:ef:4f:ab' '3e:b7:22:15:7f:a3'\n",
      " '3e:f7:f7:ce:75:72' '42:0d:76:f4:19:f7' '42:9a:ad:e0:e3:f6'\n",
      " '42:d4:39:5d:cd:0e' '46:82:86:c7:b1:72' '46:be:3e:e8:5b:02'\n",
      " '4a:f0:34:80:cc:3f' '52:4b:c5:3d:76:33' '52:56:0b:5e:25:69'\n",
      " '52:56:fe:e6:96:a9' '52:cc:c4:49:2f:5c' '56:54:b9:fa:a1:21'\n",
      " '5a:95:64:8f:b3:b6' '5a:fd:38:a4:04:c0' '5e:10:ec:1f:32:7d'\n",
      " '62:89:92:78:c8:41' '66:39:39:8f:44:ec' '66:4a:c1:26:f2:62'\n",
      " '6a:55:66:82:78:50' '6a:83:6f:53:72:19' '6a:a7:49:89:ea:df'\n",
      " '6e:49:36:21:e1:8e' '6e:bc:95:2c:43:b0' '72:23:46:5a:88:0c'\n",
      " '72:ad:7d:40:53:c8' '76:a8:e5:1f:24:37' '7a:30:c6:03:0f:db'\n",
      " '7a:63:2c:51:4e:f5' '7a:96:16:fd:3d:50' '7a:da:a6:69:9b:d8'\n",
      " '7e:60:65:97:43:ea' '7e:91:87:29:62:67' '7e:a4:4f:66:bb:92'\n",
      " '7e:d9:f2:d2:1d:ff' '82:12:1c:0f:65:e5' '82:b7:5a:db:5c:c4'\n",
      " '82:f2:e2:66:0d:fc' '86:73:12:87:0d:62' '86:e0:de:9e:32:ca'\n",
      " '8e:54:a3:6f:9c:c2' '8e:5f:d2:c9:03:c5' '92:2b:e4:8c:5d:15'\n",
      " '92:ae:50:01:10:33' '96:ef:9a:ab:c8:79' '96:fb:c3:d5:5f:dc'\n",
      " '9a:35:fa:55:52:62' '9a:ab:53:e5:6e:30' '9e:84:8b:61:7c:ef'\n",
      " '9e:9a:e2:14:c7:62' 'a6:82:13:11:40:dc' 'aa:d4:6e:ee:71:15'\n",
      " 'aa:d5:ee:f4:ae:bf' 'ae:fd:1e:7c:e9:c8' 'b2:01:c5:7f:27:4b'\n",
      " 'b2:ab:f5:f4:6a:ec' 'b6:0c:bf:df:a0:50' 'b6:1f:76:06:e8:16'\n",
      " 'b6:f3:8b:98:98:da' 'ba:88:77:4b:7a:8c' 'ba:ae:31:2f:cf:0b'\n",
      " 'be:05:40:56:af:35' 'be:43:b8:26:a5:9e' 'c2:1b:0a:42:59:50'\n",
      " 'c6:59:24:98:5d:4b' 'c6:da:6a:b3:86:fc' 'c6:e0:92:6b:61:09'\n",
      " 'ca:8f:ab:a3:01:61' 'ca:9a:c1:84:bf:6d' 'ca:a0:6b:1e:81:50'\n",
      " 'ca:de:d2:be:ba:1a' 'ce:8a:f7:cc:bc:ba' 'd2:46:92:96:89:55'\n",
      " 'd2:e8:4e:73:71:ab' 'd6:39:78:19:66:63' 'd6:bb:96:fb:eb:32'\n",
      " 'd6:eb:d0:ef:5c:ec' 'da:3c:d0:c2:0c:21' 'da:41:df:d7:34:d7'\n",
      " 'da:5f:73:c1:ec:43' 'da:b6:c3:fa:48:12' 'da:b8:41:50:18:6e'\n",
      " 'da:d8:23:79:da:25' 'de:81:f9:b5:80:46' 'de:b6:f1:0c:e7:ff'\n",
      " 'e2:05:e4:4f:fd:94' 'e2:65:c2:f0:63:60' 'e6:05:ff:97:a1:ef'\n",
      " 'e6:60:55:7b:db:39' 'e6:77:15:b2:16:d0' 'ea:3b:5b:86:87:15'\n",
      " 'ea:d0:b7:53:a8:66' 'ea:d6:ac:26:11:1c' 'ee:c4:e2:97:4c:21'\n",
      " 'f2:5a:4c:89:78:f9' 'f2:92:ec:65:b1:21' 'f2:94:c1:f2:86:9c'\n",
      " 'f2:de:ab:e4:79:c5' 'f6:02:4a:2a:55:64' 'f6:03:da:61:b9:c4'\n",
      " 'f6:14:48:57:4e:c3' 'f6:61:e8:74:79:90' 'f6:90:cb:29:ed:1b'\n",
      " 'f6:d0:02:25:77:3b' 'f6:f8:8d:83:3c:a3' 'fa:44:c9:e6:30:71'\n",
      " 'fa:57:8f:59:f4:bb' 'fa:6e:0b:1c:09:ce' 'fa:74:83:ee:9e:7c'\n",
      " 'fa:9e:cc:a2:23:6d' 'fe:0c:fb:68:17:02' 'fe:22:29:f4:b5:ac'\n",
      " 'fe:29:02:07:42:26' 'fe:79:1d:49:3b:fb' 'fe:8b:00:75:88:22']\n",
      "Encoded Labels: 0          17\n",
      "1          97\n",
      "2          35\n",
      "3         115\n",
      "4          51\n",
      "         ... \n",
      "914327     97\n",
      "914328    115\n",
      "914329     93\n",
      "914330    112\n",
      "914331    129\n",
      "Name: S_MAC, Length: 914332, dtype: object\n",
      "Unique Classes: ['02:47:6a:5a:03:6a' '02:74:55:c5:ea:d9' '06:1d:58:18:44:d2'\n",
      " '06:29:f9:52:5c:f4' '06:79:dd:3f:87:16' '0a:4d:2d:fb:69:52'\n",
      " '0a:73:ba:bb:45:43' '0a:74:47:e0:c9:03' '0a:7f:2a:8f:34:17'\n",
      " '12:2c:22:3f:8f:b7' '12:de:67:be:0a:93' '16:8b:65:9b:f2:77'\n",
      " '1a:32:84:f9:d9:11' '1a:ce:60:49:25:2c' '1a:d2:5e:86:d6:b1'\n",
      " '1e:46:fb:21:7d:ba' '26:67:1b:cb:6e:47' '26:a5:06:6e:68:0a'\n",
      " '26:b4:4f:79:f8:41' '26:e7:03:03:d1:11' '2a:3d:d0:f5:3e:1d'\n",
      " '2a:61:e1:68:04:45' '2a:ea:37:8d:de:39' '2e:29:60:92:9c:21'\n",
      " '36:3a:dc:ea:24:94' '36:6e:e9:ce:4c:a3' '3a:75:f4:62:1a:b4'\n",
      " '3a:b8:6e:ef:4f:ab' '3a:d4:c9:f6:b2:7e' '3e:b7:22:15:7f:a3'\n",
      " '3e:f7:f7:ce:75:72' '42:0d:76:f4:19:f7' '42:9a:ad:e0:e3:f6'\n",
      " '42:d4:39:5d:cd:0e' '46:be:3e:e8:5b:02' '4a:f0:34:80:cc:3f'\n",
      " '52:4b:c5:3d:76:33' '52:56:0b:5e:25:69' '52:56:fe:e6:96:a9'\n",
      " '56:54:b9:fa:a1:21' '5a:fd:38:a4:04:c0' '5e:10:ec:1f:32:7d'\n",
      " '62:89:92:78:c8:41' '62:96:19:42:3d:5f' '66:24:4d:0d:e1:00'\n",
      " '66:39:39:8f:44:ec' '66:4a:c1:26:f2:62' '66:7c:96:3f:9d:9e'\n",
      " '6a:55:66:82:78:50' '6a:83:6f:53:72:19' '6a:a7:49:89:ea:df'\n",
      " '6e:49:36:21:e1:8e' '6e:b7:66:25:a7:5e' '6e:bc:95:2c:43:b0'\n",
      " '72:23:46:5a:88:0c' '72:67:7a:d9:e2:fd' '72:ad:7d:40:53:c8'\n",
      " '76:19:4c:e0:28:a5' '7a:30:c6:03:0f:db' '7a:63:2c:51:4e:f5'\n",
      " '7a:da:a6:69:9b:d8' '7a:e3:0d:64:1b:7a' '7e:60:65:97:43:ea'\n",
      " '7e:91:87:29:62:67' '7e:a4:4f:66:bb:92' '82:12:1c:0f:65:e5'\n",
      " '82:b7:5a:db:5c:c4' '82:f2:e2:66:0d:fc' '86:73:12:87:0d:62'\n",
      " '86:e0:de:9e:32:ca' '8a:87:7d:38:4d:d2' '8e:5f:d2:c9:03:c5'\n",
      " '92:2b:e4:8c:5d:15' '96:fb:c3:d5:5f:dc' '9a:35:fa:55:52:62'\n",
      " '9a:ab:53:e5:6e:30' '9e:68:c7:15:ff:56' '9e:84:8b:61:7c:ef'\n",
      " '9e:9a:e2:14:c7:62' 'aa:d4:6e:ee:71:15' 'aa:d5:ee:f4:ae:bf'\n",
      " 'ae:fd:1e:7c:e9:c8' 'b2:01:c5:7f:27:4b' 'b6:0c:bf:df:a0:50'\n",
      " 'b6:1f:76:06:e8:16' 'ba:ae:31:2f:cf:0b' 'be:05:40:56:af:35'\n",
      " 'be:43:b8:26:a5:9e' 'c6:59:24:98:5d:4b' 'c6:e0:92:6b:61:09'\n",
      " 'ca:9a:c1:84:bf:6d' 'ca:de:d2:be:ba:1a' 'ce:8a:f7:cc:bc:ba'\n",
      " 'd2:46:92:96:89:55' 'd2:84:86:c4:4d:e3' 'd2:c4:88:e3:23:70'\n",
      " 'd2:e8:4e:73:71:ab' 'd6:a5:b5:2d:62:5b' 'd6:bb:96:fb:eb:32'\n",
      " 'd6:eb:d0:ef:5c:ec' 'da:41:df:d7:34:d7' 'da:5f:73:c1:ec:43'\n",
      " 'da:b6:c3:fa:48:12' 'da:d8:23:79:da:25' 'de:81:f9:b5:80:46'\n",
      " 'de:b6:f1:0c:e7:ff' 'e2:05:e4:4f:fd:94' 'e2:65:c2:f0:63:60'\n",
      " 'e6:05:ff:97:a1:ef' 'e6:60:55:7b:db:39' 'ea:d6:ac:26:11:1c'\n",
      " 'ea:ff:a2:e9:10:ad' 'ee:c4:e2:97:4c:21' 'f2:5a:4c:89:78:f9'\n",
      " 'f2:92:ec:65:b1:21' 'f6:02:4a:2a:55:64' 'f6:03:da:61:b9:c4'\n",
      " 'f6:14:48:57:4e:c3' 'f6:61:e8:74:79:90' 'f6:90:cb:29:ed:1b'\n",
      " 'f6:d0:02:25:77:3b' 'f6:f8:8d:83:3c:a3' 'fa:44:c9:e6:30:71'\n",
      " 'fa:57:8f:59:f4:bb' 'fa:6e:0b:1c:09:ce' 'fa:9e:cc:a2:23:6d'\n",
      " 'fe:0c:fb:68:17:02' 'fe:22:29:f4:b5:ac' 'fe:79:1d:49:3b:fb'\n",
      " 'fe:8b:00:75:88:22']\n",
      "Encoded Labels: 0         95\n",
      "1         52\n",
      "2         44\n",
      "3         61\n",
      "4         43\n",
      "          ..\n",
      "914327    52\n",
      "914328    61\n",
      "914329    43\n",
      "914330    76\n",
      "914331    43\n",
      "Name: D_MAC, Length: 914332, dtype: object\n",
      "Unique Classes: ['0.0.139.166' '0.0.141.91' '0.0.2.186' ... '99.99.79.225' '99.99.79.80'\n",
      " '99.99.96.135']\n",
      "Encoded Labels: 0         357824\n",
      "1         322577\n",
      "2         207946\n",
      "3           3333\n",
      "4         105254\n",
      "           ...  \n",
      "914327     39788\n",
      "914328      3352\n",
      "914329    285844\n",
      "914330      3349\n",
      "914331     35897\n",
      "Name: SIP, Length: 914332, dtype: object\n",
      "Unique Classes: ['10.0.0.1' '10.0.0.10' '10.0.0.11' '10.0.0.12' '10.0.0.13' '10.0.0.14'\n",
      " '10.0.0.15' '10.0.0.16' '10.0.0.17' '10.0.0.18' '10.0.0.19' '10.0.0.2'\n",
      " '10.0.0.20' '10.0.0.21' '10.0.0.22' '10.0.0.23' '10.0.0.3' '10.0.0.4'\n",
      " '10.0.0.5' '10.0.0.6' '10.0.0.7' '10.0.0.8' '10.0.0.9']\n",
      "Encoded Labels: 0          3\n",
      "1          0\n",
      "2          4\n",
      "3          7\n",
      "4          2\n",
      "          ..\n",
      "914327     0\n",
      "914328     7\n",
      "914329     2\n",
      "914330    16\n",
      "914331     2\n",
      "Name: DIP, Length: 914332, dtype: object\n",
      "Unique Classes: ['attack' 'normal']\n",
      "Encoded Labels: 0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "914327    0\n",
      "914328    0\n",
      "914329    0\n",
      "914330    0\n",
      "914331    0\n",
      "Name: label, Length: 914332, dtype: object\n",
      "Unique Classes: ['Bhttp_flood.pcap' 'Bicmp_flood.pcap' 'Bmqtt_udp_flood.pcap'\n",
      " 'Btcp_flood.pcap' 'Budp_flood.pcap' 'Hicmp_flood.pcap' 'Htcp_flood.pcap'\n",
      " 'Hudp_flood.pcap' 'hmqtt_TcpSyn_flood.pcap' 'mqtt_publish_flood1.pcap'\n",
      " 'normal']\n",
      "Encoded Labels: 0         7\n",
      "1         5\n",
      "2         6\n",
      "3         3\n",
      "4         8\n",
      "         ..\n",
      "914327    5\n",
      "914328    3\n",
      "914329    8\n",
      "914330    4\n",
      "914331    8\n",
      "Name: type, Length: 914332, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X=encod(X)\n",
    "EY=encod(Y)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)\n",
    "# X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature 25, Accuracy: 0.90832\n",
      "Selected feature 35, Accuracy: 0.91353\n",
      "Selected feature 40, Accuracy: 0.94324\n",
      "Selected feature 39, Accuracy: 0.94844\n",
      "Selected feature 29, Accuracy: 0.95264\n",
      "Selected feature 65, Accuracy: 0.95485\n",
      "Selected feature 45, Accuracy: 0.95551\n",
      "Selected feature 2, Accuracy: 0.95644\n",
      "Selected feature 61, Accuracy: 0.95708\n",
      "Selected feature 12, Accuracy: 0.95740\n",
      "Selected feature 33, Accuracy: 0.95766\n",
      "Selected feature 43, Accuracy: 0.95782\n",
      "Selected feature 8, Accuracy: 0.95803\n",
      "Selected feature 9, Accuracy: 0.95816\n",
      "Selected feature 3, Accuracy: 0.95841\n",
      "Selected feature 53, Accuracy: 0.95890\n",
      "Selected feature 55, Accuracy: 0.95905\n",
      "Selected feature 0, Accuracy: 0.95950\n",
      "Selected feature 23, Accuracy: 0.95954\n",
      "Selected feature 1, Accuracy: 0.95960\n",
      "Selected feature 63, Accuracy: 0.95964\n",
      "Selected feature 21, Accuracy: 0.95968\n",
      "Selected feature 60, Accuracy: 0.95970\n",
      "Selected feature 42, Accuracy: 0.95970\n",
      "Selected feature 6, Accuracy: 0.95971\n",
      "Selected feature 5, Accuracy: 0.95972\n",
      "Selected feature 7, Accuracy: 0.95972\n",
      "Selected feature 62, Accuracy: 0.95973\n",
      "Selected feature 15, Accuracy: 0.95974\n",
      "Selected feature 27, Accuracy: 0.95975\n",
      "Selected feature 44, Accuracy: 0.95976\n",
      "Selected feature 41, Accuracy: 0.95984\n",
      "Selected feature 10, Accuracy: 0.95985\n",
      "Selected feature 47, Accuracy: 0.95985\n",
      "Selected features: [25, 35, 40, 39, 29, 65, 45, 2, 61, 12, 33, 43, 8, 9, 3, 53, 55, 0, 23, 1, 63, 21, 60, 42, 6, 5, 7, 62, 15, 27, 44, 41, 10, 47]\n"
     ]
    }
   ],
   "source": [
    "# device Identification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled.iloc[:,:],EY.iloc[:,-2].astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = RidgeClassifier()\n",
    "# kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "# clf = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "def evaluate_features(clf,features,X_train,y_train,y_test):\n",
    "    clf.fit(X_train.iloc[:,features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Perform wrapper feature selection\n",
    "num_features = X_train.shape[1]\n",
    "selected_features = []\n",
    "best_accuracy = 0\n",
    "\n",
    "for _ in range(num_features):\n",
    "    best_feature = None\n",
    "    for feature in range(num_features):\n",
    "        if feature not in selected_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            #print(current_features)\n",
    "            accuracy = evaluate_features(clf,current_features,X_train,y_train,y_test)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_feature = feature\n",
    "    if best_feature is not None:\n",
    "        selected_features.append(best_feature)\n",
    "        print(f\"Selected feature {best_feature}, Accuracy: {best_accuracy:.5f}\")\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FAPS', 'RTT', 'FIN_FC', 'SYN_FC', 'Proto', 'D_type', 'DACount',\n",
       "       'FAMean', 'HTTPRM_L', 'TBytes', 'BytesPS', 'TCP_HD', 'FIStd', 'DSCP_C',\n",
       "       'FAMax', 'PIA_Var', 'PEntropy', 'FD', 'FlowV', 'FAMin', 'HTTP_SCL',\n",
       "       'FlowR', 'TCPWS_Mode', 'PSH_FC', 'FIMin', 'FIMean', 'FIMax',\n",
       "       'HTTPRM_UL', 'PLM', 'FBPP', 'RCount', 'RST_FC', 'ECN_C', 'FThroughput'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[:,selected_features].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func for missing values imputation, encoding, and normalization\n",
    "\n",
    "def encod(data):\n",
    "  from sklearn import preprocessing\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "  try:\n",
    "    n=data.shape[1]\n",
    "    for i in range(n):\n",
    "      if data.iloc[:,i].dtype == 'object':\n",
    "\n",
    "        data.iloc[:,i]= label_encoder.fit_transform(data.iloc[:,i])\n",
    "        unique_classes = label_encoder.classes_\n",
    "        print(\"Unique Classes:\", unique_classes)\n",
    "        print(\"Encoded Labels:\", data.iloc[:,i])\n",
    "    return data\n",
    "  except:\n",
    "    if data.dtype == 'object':\n",
    "      n=len(data)\n",
    "      data= label_encoder.fit_transform(data)\n",
    "    return data\n",
    "  \n",
    "\n",
    "\n",
    "def normalize_scale(X):\n",
    "  m= X.values #returns a numpy array\n",
    "  cols_name = X.columns\n",
    "  scaler = preprocessing.MinMaxScaler()\n",
    "  x_scaled = scaler.fit_transform(m)\n",
    "  #scaler.transform(X) for scaling using the previous weights\n",
    "  Scale_X = pd.DataFrame(x_scaled,columns = cols_name)\n",
    "  return Scale_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FAPS', 'RTT', 'FIN_FC', 'SYN_FC', 'Proto', 'D_type', 'DACount',\n",
       "       'FAMean', 'HTTPRM_L', 'TBytes', 'BytesPS', 'TCP_HD', 'FIStd', 'DSCP_C',\n",
       "       'FAMax', 'PIA_Var', 'PEntropy', 'FD', 'FlowV', 'FAMin', 'HTTP_SCL',\n",
       "       'FlowR', 'TCPWS_Mode', 'PSH_FC', 'FIMin', 'FIMean', 'FIMax',\n",
       "       'HTTPRM_UL', 'PLM', 'FBPP', 'RCount', 'RST_FC', 'ECN_C', 'FThroughput'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=X_train.iloc[:,selected_features].columns\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes: ['CD' 'IoT' 'NU']\n",
      "Encoded Labels: 0         2\n",
      "1         2\n",
      "2         2\n",
      "3         2\n",
      "4         1\n",
      "         ..\n",
      "914327    2\n",
      "914328    2\n",
      "914329    1\n",
      "914330    2\n",
      "914331    1\n",
      "Name: D_type, Length: 914332, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)\n",
    "X=data[b]\n",
    "X=encod(X)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)\n",
    "\n",
    "EY=encod(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95985\n",
      "Precision: 0.95865\n",
      "Recall: 0.95985\n",
      "F1-score: 0.95663\n",
      "MCC: 0.75186\n",
      "Average Prediction Time: 16.1570 ms\n"
     ]
    }
   ],
   "source": [
    "# device identification\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = RidgeClassifier()\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FIN_FC', 'TCPWS_Mean', 'RTT', 'FIMin', 'FAMean', 'HTTPRM_UL', 'FD',\n",
       "       'TCP_HD', 'DACount', 'HTTP_SCL', 'FEntropy', 'FlowStd', 'TCPWS_Mode',\n",
       "       'FlowV', 'PIA_Var', 'PLM', 'RST_FC', 'RCount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=X_train.iloc[:,selected_features].columns\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=['FIN_FC', 'TCPWS_Mean', 'RTT', 'FIMin', 'FAMean', 'HTTPRM_UL', 'FD', 'TCP_HD', 'DACount', 'HTTP_SCL', 'FEntropy', 'FlowStd', 'TCPWS_Mode', 'FlowV', 'PIA_Var', 'PLM', 'RST_FC', 'RCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)\n",
    "X=data[a]\n",
    "X=encod(X)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)\n",
    "\n",
    "EY=encod(data['D_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68707\n",
      "Precision: 0.76340\n",
      "Recall: 0.68707\n",
      "F1-score: 0.63191\n",
      "MCC: 0.39814\n",
      "Average Prediction Time: 16.1569 ms\n"
     ]
    }
   ],
   "source": [
    "# device identification\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = RidgeClassifier()\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature 25, Accuracy: 0.90832\n",
      "Selected feature 35, Accuracy: 0.91353\n",
      "Selected feature 40, Accuracy: 0.94324\n",
      "Selected feature 39, Accuracy: 0.94844\n",
      "Selected feature 29, Accuracy: 0.95264\n",
      "Selected feature 22, Accuracy: 0.95406\n",
      "Selected feature 61, Accuracy: 0.95473\n",
      "Selected feature 33, Accuracy: 0.95491\n",
      "Selected feature 21, Accuracy: 0.95498\n",
      "Selected feature 12, Accuracy: 0.95504\n",
      "Selected feature 58, Accuracy: 0.95534\n",
      "Selected feature 9, Accuracy: 0.95564\n",
      "Selected feature 45, Accuracy: 0.95593\n",
      "Selected feature 63, Accuracy: 0.95605\n",
      "Selected feature 6, Accuracy: 0.95620\n",
      "Selected feature 43, Accuracy: 0.95633\n",
      "Selected feature 60, Accuracy: 0.95641\n",
      "Selected feature 44, Accuracy: 0.95642\n",
      "Selected feature 41, Accuracy: 0.95652\n",
      "Selected feature 37, Accuracy: 0.95654\n",
      "Selected feature 13, Accuracy: 0.95655\n",
      "Selected feature 62, Accuracy: 0.95656\n",
      "Selected feature 42, Accuracy: 0.95656\n",
      "Selected feature 47, Accuracy: 0.95657\n",
      "Selected features: [25, 35, 40, 39, 29, 22, 61, 33, 21, 12, 58, 9, 45, 63, 6, 43, 60, 44, 41, 37, 13, 62, 42, 47]\n"
     ]
    }
   ],
   "source": [
    "# Attack Identification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled.iloc[:,:],EY.iloc[:,-3].astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = RidgeClassifier()\n",
    "# kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "# clf = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "def evaluate_features(clf,features,X_train,y_train,y_test):\n",
    "    clf.fit(X_train.iloc[:,features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Perform wrapper feature selection\n",
    "num_features = X_train.shape[1]\n",
    "selected_features = []\n",
    "best_accuracy = 0\n",
    "\n",
    "for _ in range(num_features):\n",
    "    best_feature = None\n",
    "    for feature in range(num_features):\n",
    "        if feature not in selected_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            #print(current_features)\n",
    "            accuracy = evaluate_features(clf,current_features,X_train,y_train,y_test)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_feature = feature\n",
    "    if best_feature is not None:\n",
    "        selected_features.append(best_feature)\n",
    "        print(f\"Selected feature {best_feature}, Accuracy: {best_accuracy:.5f}\")\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FAPS', 'RTT', 'FIN_FC', 'SYN_FC', 'Proto', 'FlowStd', 'HTTPRM_L',\n",
       "       'BytesPS', 'FlowR', 'TBytes', 'TCPWS_Sum', 'DSCP_C', 'DACount',\n",
       "       'HTTP_SCL', 'FIMin', 'TCP_HD', 'TCPWS_Mode', 'RCount', 'RST_FC',\n",
       "       'HL_Mode', 'SBytes', 'HTTPRM_UL', 'PSH_FC', 'FThroughput'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=X.iloc[:,[25, 35, 40, 39, 29, 22, 61, 33, 21, 12, 58, 9, 45, 63, 6, 43, 60, 44, 41, 37, 13, 62, 42, 47]].columns\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func for missing values imputation, encoding, and normalization\n",
    "\n",
    "def encod(data):\n",
    "  from sklearn import preprocessing\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "  try:\n",
    "    n=data.shape[1]\n",
    "    for i in range(n):\n",
    "      if data.iloc[:,i].dtype == 'object':\n",
    "\n",
    "        data.iloc[:,i]= label_encoder.fit_transform(data.iloc[:,i])\n",
    "        unique_classes = label_encoder.classes_\n",
    "        print(\"Unique Classes:\", unique_classes)\n",
    "        print(\"Encoded Labels:\", data.iloc[:,i])\n",
    "    return data\n",
    "  except:\n",
    "    if data.dtype == 'object':\n",
    "      n=len(data)\n",
    "      data= label_encoder.fit_transform(data)\n",
    "    return data\n",
    "  \n",
    "\n",
    "\n",
    "def normalize_scale(X):\n",
    "  m= X.values #returns a numpy array\n",
    "  cols_name = X.columns\n",
    "  scaler = preprocessing.MinMaxScaler()\n",
    "  x_scaled = scaler.fit_transform(m)\n",
    "  #scaler.transform(X) for scaling using the previous weights\n",
    "  Scale_X = pd.DataFrame(x_scaled,columns = cols_name)\n",
    "  return Scale_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)\n",
    "X=data[a]\n",
    "X=encod(X)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)\n",
    "\n",
    "EY=encod(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95657\n",
      "Precision: 0.95507\n",
      "Recall: 0.95657\n",
      "F1-score: 0.95273\n",
      "MCC: 0.72912\n",
      "Average Prediction Time: 13.4498 ms\n"
     ]
    }
   ],
   "source": [
    "# Attack detection + D_type\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = RidgeClassifier()\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)\n",
    "ID_Features=['S_MAC',\n",
    "'D_MAC',\n",
    "'FPT',\n",
    "'LPT',\n",
    "'SIT',\n",
    "'STT',\n",
    "'SIP',\n",
    "'DIP',\n",
    "'SPort',\n",
    "'DPort',\n",
    "'label',\n",
    "'type', 'D_type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func for missing values imputation, encoding, and normalization\n",
    "\n",
    "def encod(data):\n",
    "  from sklearn import preprocessing\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "  try:\n",
    "    n=data.shape[1]\n",
    "    for i in range(n):\n",
    "      if data.iloc[:,i].dtype == 'object':\n",
    "\n",
    "        data.iloc[:,i]= label_encoder.fit_transform(data.iloc[:,i])\n",
    "        unique_classes = label_encoder.classes_\n",
    "        print(\"Unique Classes:\", unique_classes)\n",
    "        print(\"Encoded Labels:\", data.iloc[:,i])\n",
    "    return data\n",
    "  except:\n",
    "    if data.dtype == 'object':\n",
    "      n=len(data)\n",
    "      data= label_encoder.fit_transform(data)\n",
    "    return data\n",
    "  \n",
    "\n",
    "\n",
    "def normalize_scale(X):\n",
    "  m= X.values #returns a numpy array\n",
    "  cols_name = X.columns\n",
    "  scaler = preprocessing.MinMaxScaler()\n",
    "  x_scaled = scaler.fit_transform(m)\n",
    "  #scaler.transform(X) for scaling using the previous weights\n",
    "  Scale_X = pd.DataFrame(x_scaled,columns = cols_name)\n",
    "  return Scale_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data[ID_Features]\n",
    "X=data.drop(ID_Features,axis=1)\n",
    "for i in X:\n",
    "      if X[i].dtype == 'object':\n",
    "            print(i)\n",
    "# no categorical data type\n",
    "X=encod(X)\n",
    "EY=encod(Y['label'])\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature 4, Accuracy: 0.99950\n",
      "Selected feature 24, Accuracy: 0.99950\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# clf = RandomForestClassifier(random_state=42)\n",
    "clf=ExtraTreesClassifier()\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "def evaluate_features(clf,features,X_train,y_train,y_test):\n",
    "    clf.fit(X_train.iloc[:,features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Perform wrapper feature selection\n",
    "num_features = X_train.shape[1]\n",
    "selected_features = [52,58,35,40,59,23,27,34,45,37,57,41,47,22,42,50,32,12,31,5,62,4,24]\n",
    "best_accuracy = 0\n",
    "\n",
    "for _ in range(num_features):\n",
    "    best_feature = None\n",
    "    for feature in range(num_features):\n",
    "        if feature not in selected_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            #print(current_features)\n",
    "            accuracy = evaluate_features(clf,current_features,X_train,y_train,y_test)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_feature = feature\n",
    "    if best_feature is not None:\n",
    "        selected_features.append(best_feature)\n",
    "        print(f\"Selected feature {best_feature}, Accuracy: {best_accuracy:.5f}\")\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FEntropy', 'TCPWS_Sum', 'RTT', 'FIN_FC', 'TCPWS_Mean', 'FlowV', 'FBPP',\n",
       "       'PacketsPS', 'DACount', 'HL_Mode', 'BIPD_Var', 'RST_FC', 'FThroughput',\n",
       "       'FlowStd', 'PSH_FC', 'BJitter', 'SBCount', 'TBytes', 'SPC', 'FIMean',\n",
       "       'HTTPRM_UL', 'FAStd', 'FH_M'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SF=X_train_scaled.iloc[:,[52,58,35,40,59,23,27,34,45,37,57,41,47,22,42,50,32,12,31,5,62,4,24]].columns\n",
    "SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)\n",
    "ID_Features=['S_MAC',\n",
    "'D_MAC',\n",
    "'FPT',\n",
    "'LPT',\n",
    "'SIT',\n",
    "'STT',\n",
    "'SIP',\n",
    "'DIP',\n",
    "'SPort',\n",
    "'DPort',\n",
    "'label',\n",
    "'type']\n",
    "#, 'D_type']\n",
    "\n",
    "def encod(data):\n",
    "  from sklearn import preprocessing\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "  try:\n",
    "    n=data.shape[1]\n",
    "    for i in range(n):\n",
    "      if data.iloc[:,i].dtype == 'object':\n",
    "\n",
    "        data.iloc[:,i]= label_encoder.fit_transform(data.iloc[:,i])\n",
    "        unique_classes = label_encoder.classes_\n",
    "        print(\"Unique Classes:\", unique_classes)\n",
    "        print(\"Encoded Labels:\", data.iloc[:,i])\n",
    "    return data\n",
    "  except:\n",
    "    if data.dtype == 'object':\n",
    "      n=len(data)\n",
    "      data= label_encoder.fit_transform(data)\n",
    "    return data\n",
    "  \n",
    "\n",
    "\n",
    "def normalize_scale(X):\n",
    "  m= X.values #returns a numpy array\n",
    "  cols_name = X.columns\n",
    "  scaler = preprocessing.MinMaxScaler()\n",
    "  x_scaled = scaler.fit_transform(m)\n",
    "  #scaler.transform(X) for scaling using the previous weights\n",
    "  Scale_X = pd.DataFrame(x_scaled,columns = cols_name)\n",
    "  return Scale_X\n",
    "\n",
    "Y=data[ID_Features]\n",
    "X=data[SF]\n",
    "for i in X:\n",
    "      if X[i].dtype == 'object':\n",
    "            print(i)\n",
    "# no categorical data type\n",
    "X=encod(X)\n",
    "EY=encod(Y['label'])\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99947\n",
      "Precision: 0.99947\n",
      "Recall: 0.99947\n",
      "F1-score: 0.99947\n",
      "MCC: 0.99700\n",
      "Average Prediction Time: 2046.3899 ms\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = ExtraTreesClassifier()\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID_Features=['S_MAC',\n",
    "# 'D_MAC',\n",
    "# 'FPT',\n",
    "# 'LPT',\n",
    "# 'SIT',\n",
    "# 'STT',\n",
    "# 'SIP',\n",
    "# 'DIP',\n",
    "# 'SPort',\n",
    "# 'DPort',\n",
    "# 'label',\n",
    "# 'type']\n",
    "\n",
    "ID_Features=['S_MAC',\n",
    "'D_MAC',\n",
    "'FPT',\n",
    "'LPT',\n",
    "'SIT',\n",
    "'STT',\n",
    "'SIP',\n",
    "'DIP',\n",
    "'SPort',\n",
    "'DPort',\n",
    "'label',\n",
    "'type']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_type\n"
     ]
    }
   ],
   "source": [
    "Y=data[ID_Features]\n",
    "X=data.drop(ID_Features,axis=1)\n",
    "\n",
    "for i in X:\n",
    "      if X[i].dtype == 'object':\n",
    "            print(i)\n",
    "\n",
    "\n",
    "\n",
    "# func for missing values imputation, encoding, and normalization\n",
    "\n",
    "def encod(data):\n",
    "  n=data.shape[1]\n",
    "  from sklearn import preprocessing\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "  for i in range(n):\n",
    "      if data.iloc[:,i].dtype == 'object':\n",
    "\n",
    "        data.iloc[:,i]= label_encoder.fit_transform(data.iloc[:,i])\n",
    "        unique_classes = label_encoder.classes_\n",
    "        print(\"Unique Classes:\", unique_classes)\n",
    "        print(\"Encoded Labels:\", data.iloc[:,i])\n",
    "  return data\n",
    "\n",
    "\n",
    "def normalize_scale(X):\n",
    "  m= X.values #returns a numpy array\n",
    "  cols_name = X.columns\n",
    "  scaler = preprocessing.MinMaxScaler()\n",
    "  x_scaled = scaler.fit_transform(m)\n",
    "  #scaler.transform(X) for scaling using the previous weights\n",
    "  Scale_X = pd.DataFrame(x_scaled,columns = cols_name)\n",
    "  return Scale_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes: ['CD' 'IoT' 'NU']\n",
      "Encoded Labels: 0         2\n",
      "1         2\n",
      "2         2\n",
      "3         2\n",
      "4         1\n",
      "         ..\n",
      "914327    2\n",
      "914328    2\n",
      "914329    1\n",
      "914330    2\n",
      "914331    1\n",
      "Name: D_type, Length: 914332, dtype: object\n",
      "Unique Classes: ['02:3e:c2:98:b6:13' '02:47:6a:5a:03:6a' '02:74:55:c5:ea:d9'\n",
      " '06:1d:58:18:44:d2' '06:29:f9:52:5c:f4' '06:79:dd:3f:87:16'\n",
      " '0a:4d:2d:fb:69:52' '0a:73:ba:bb:45:43' '0a:74:47:e0:c9:03'\n",
      " '0a:7f:2a:8f:34:17' '0e:3f:d9:e6:6b:75' '12:2c:22:3f:8f:b7'\n",
      " '12:44:cd:3f:90:39' '12:de:67:be:0a:93' '16:8b:65:9b:f2:77'\n",
      " '1a:32:84:f9:d9:11' '1a:b5:24:b1:05:47' '1a:bf:56:94:b7:a2'\n",
      " '1a:ce:60:49:25:2c' '1a:d2:5e:86:d6:b1' '1e:46:fb:21:7d:ba'\n",
      " '1e:5a:47:93:77:3d' '1e:66:8b:37:9b:d5' '26:22:86:56:9e:59'\n",
      " '26:67:1b:cb:6e:47' '26:a5:06:6e:68:0a' '26:b4:4f:79:f8:41'\n",
      " '26:e7:03:03:d1:11' '2a:61:e1:68:04:45' '2a:6d:30:53:12:a1'\n",
      " '2a:ea:37:8d:de:39' '2e:29:60:92:9c:21' '36:3a:dc:ea:24:94'\n",
      " '36:6e:e9:ce:4c:a3' '36:f0:f2:07:c6:77' '3a:0e:4c:1c:c8:2f'\n",
      " '3a:75:f4:62:1a:b4' '3a:b8:6e:ef:4f:ab' '3e:b7:22:15:7f:a3'\n",
      " '3e:f7:f7:ce:75:72' '42:0d:76:f4:19:f7' '42:9a:ad:e0:e3:f6'\n",
      " '42:d4:39:5d:cd:0e' '46:82:86:c7:b1:72' '46:be:3e:e8:5b:02'\n",
      " '4a:f0:34:80:cc:3f' '52:4b:c5:3d:76:33' '52:56:0b:5e:25:69'\n",
      " '52:56:fe:e6:96:a9' '52:cc:c4:49:2f:5c' '56:54:b9:fa:a1:21'\n",
      " '5a:95:64:8f:b3:b6' '5a:fd:38:a4:04:c0' '5e:10:ec:1f:32:7d'\n",
      " '62:89:92:78:c8:41' '66:39:39:8f:44:ec' '66:4a:c1:26:f2:62'\n",
      " '6a:55:66:82:78:50' '6a:83:6f:53:72:19' '6a:a7:49:89:ea:df'\n",
      " '6e:49:36:21:e1:8e' '6e:bc:95:2c:43:b0' '72:23:46:5a:88:0c'\n",
      " '72:ad:7d:40:53:c8' '76:a8:e5:1f:24:37' '7a:30:c6:03:0f:db'\n",
      " '7a:63:2c:51:4e:f5' '7a:96:16:fd:3d:50' '7a:da:a6:69:9b:d8'\n",
      " '7e:60:65:97:43:ea' '7e:91:87:29:62:67' '7e:a4:4f:66:bb:92'\n",
      " '7e:d9:f2:d2:1d:ff' '82:12:1c:0f:65:e5' '82:b7:5a:db:5c:c4'\n",
      " '82:f2:e2:66:0d:fc' '86:73:12:87:0d:62' '86:e0:de:9e:32:ca'\n",
      " '8e:54:a3:6f:9c:c2' '8e:5f:d2:c9:03:c5' '92:2b:e4:8c:5d:15'\n",
      " '92:ae:50:01:10:33' '96:ef:9a:ab:c8:79' '96:fb:c3:d5:5f:dc'\n",
      " '9a:35:fa:55:52:62' '9a:ab:53:e5:6e:30' '9e:84:8b:61:7c:ef'\n",
      " '9e:9a:e2:14:c7:62' 'a6:82:13:11:40:dc' 'aa:d4:6e:ee:71:15'\n",
      " 'aa:d5:ee:f4:ae:bf' 'ae:fd:1e:7c:e9:c8' 'b2:01:c5:7f:27:4b'\n",
      " 'b2:ab:f5:f4:6a:ec' 'b6:0c:bf:df:a0:50' 'b6:1f:76:06:e8:16'\n",
      " 'b6:f3:8b:98:98:da' 'ba:88:77:4b:7a:8c' 'ba:ae:31:2f:cf:0b'\n",
      " 'be:05:40:56:af:35' 'be:43:b8:26:a5:9e' 'c2:1b:0a:42:59:50'\n",
      " 'c6:59:24:98:5d:4b' 'c6:da:6a:b3:86:fc' 'c6:e0:92:6b:61:09'\n",
      " 'ca:8f:ab:a3:01:61' 'ca:9a:c1:84:bf:6d' 'ca:a0:6b:1e:81:50'\n",
      " 'ca:de:d2:be:ba:1a' 'ce:8a:f7:cc:bc:ba' 'd2:46:92:96:89:55'\n",
      " 'd2:e8:4e:73:71:ab' 'd6:39:78:19:66:63' 'd6:bb:96:fb:eb:32'\n",
      " 'd6:eb:d0:ef:5c:ec' 'da:3c:d0:c2:0c:21' 'da:41:df:d7:34:d7'\n",
      " 'da:5f:73:c1:ec:43' 'da:b6:c3:fa:48:12' 'da:b8:41:50:18:6e'\n",
      " 'da:d8:23:79:da:25' 'de:81:f9:b5:80:46' 'de:b6:f1:0c:e7:ff'\n",
      " 'e2:05:e4:4f:fd:94' 'e2:65:c2:f0:63:60' 'e6:05:ff:97:a1:ef'\n",
      " 'e6:60:55:7b:db:39' 'e6:77:15:b2:16:d0' 'ea:3b:5b:86:87:15'\n",
      " 'ea:d0:b7:53:a8:66' 'ea:d6:ac:26:11:1c' 'ee:c4:e2:97:4c:21'\n",
      " 'f2:5a:4c:89:78:f9' 'f2:92:ec:65:b1:21' 'f2:94:c1:f2:86:9c'\n",
      " 'f2:de:ab:e4:79:c5' 'f6:02:4a:2a:55:64' 'f6:03:da:61:b9:c4'\n",
      " 'f6:14:48:57:4e:c3' 'f6:61:e8:74:79:90' 'f6:90:cb:29:ed:1b'\n",
      " 'f6:d0:02:25:77:3b' 'f6:f8:8d:83:3c:a3' 'fa:44:c9:e6:30:71'\n",
      " 'fa:57:8f:59:f4:bb' 'fa:6e:0b:1c:09:ce' 'fa:74:83:ee:9e:7c'\n",
      " 'fa:9e:cc:a2:23:6d' 'fe:0c:fb:68:17:02' 'fe:22:29:f4:b5:ac'\n",
      " 'fe:29:02:07:42:26' 'fe:79:1d:49:3b:fb' 'fe:8b:00:75:88:22']\n",
      "Encoded Labels: 0          17\n",
      "1          97\n",
      "2          35\n",
      "3         115\n",
      "4          51\n",
      "         ... \n",
      "914327     97\n",
      "914328    115\n",
      "914329     93\n",
      "914330    112\n",
      "914331    129\n",
      "Name: S_MAC, Length: 914332, dtype: object\n",
      "Unique Classes: ['02:47:6a:5a:03:6a' '02:74:55:c5:ea:d9' '06:1d:58:18:44:d2'\n",
      " '06:29:f9:52:5c:f4' '06:79:dd:3f:87:16' '0a:4d:2d:fb:69:52'\n",
      " '0a:73:ba:bb:45:43' '0a:74:47:e0:c9:03' '0a:7f:2a:8f:34:17'\n",
      " '12:2c:22:3f:8f:b7' '12:de:67:be:0a:93' '16:8b:65:9b:f2:77'\n",
      " '1a:32:84:f9:d9:11' '1a:ce:60:49:25:2c' '1a:d2:5e:86:d6:b1'\n",
      " '1e:46:fb:21:7d:ba' '26:67:1b:cb:6e:47' '26:a5:06:6e:68:0a'\n",
      " '26:b4:4f:79:f8:41' '26:e7:03:03:d1:11' '2a:3d:d0:f5:3e:1d'\n",
      " '2a:61:e1:68:04:45' '2a:ea:37:8d:de:39' '2e:29:60:92:9c:21'\n",
      " '36:3a:dc:ea:24:94' '36:6e:e9:ce:4c:a3' '3a:75:f4:62:1a:b4'\n",
      " '3a:b8:6e:ef:4f:ab' '3a:d4:c9:f6:b2:7e' '3e:b7:22:15:7f:a3'\n",
      " '3e:f7:f7:ce:75:72' '42:0d:76:f4:19:f7' '42:9a:ad:e0:e3:f6'\n",
      " '42:d4:39:5d:cd:0e' '46:be:3e:e8:5b:02' '4a:f0:34:80:cc:3f'\n",
      " '52:4b:c5:3d:76:33' '52:56:0b:5e:25:69' '52:56:fe:e6:96:a9'\n",
      " '56:54:b9:fa:a1:21' '5a:fd:38:a4:04:c0' '5e:10:ec:1f:32:7d'\n",
      " '62:89:92:78:c8:41' '62:96:19:42:3d:5f' '66:24:4d:0d:e1:00'\n",
      " '66:39:39:8f:44:ec' '66:4a:c1:26:f2:62' '66:7c:96:3f:9d:9e'\n",
      " '6a:55:66:82:78:50' '6a:83:6f:53:72:19' '6a:a7:49:89:ea:df'\n",
      " '6e:49:36:21:e1:8e' '6e:b7:66:25:a7:5e' '6e:bc:95:2c:43:b0'\n",
      " '72:23:46:5a:88:0c' '72:67:7a:d9:e2:fd' '72:ad:7d:40:53:c8'\n",
      " '76:19:4c:e0:28:a5' '7a:30:c6:03:0f:db' '7a:63:2c:51:4e:f5'\n",
      " '7a:da:a6:69:9b:d8' '7a:e3:0d:64:1b:7a' '7e:60:65:97:43:ea'\n",
      " '7e:91:87:29:62:67' '7e:a4:4f:66:bb:92' '82:12:1c:0f:65:e5'\n",
      " '82:b7:5a:db:5c:c4' '82:f2:e2:66:0d:fc' '86:73:12:87:0d:62'\n",
      " '86:e0:de:9e:32:ca' '8a:87:7d:38:4d:d2' '8e:5f:d2:c9:03:c5'\n",
      " '92:2b:e4:8c:5d:15' '96:fb:c3:d5:5f:dc' '9a:35:fa:55:52:62'\n",
      " '9a:ab:53:e5:6e:30' '9e:68:c7:15:ff:56' '9e:84:8b:61:7c:ef'\n",
      " '9e:9a:e2:14:c7:62' 'aa:d4:6e:ee:71:15' 'aa:d5:ee:f4:ae:bf'\n",
      " 'ae:fd:1e:7c:e9:c8' 'b2:01:c5:7f:27:4b' 'b6:0c:bf:df:a0:50'\n",
      " 'b6:1f:76:06:e8:16' 'ba:ae:31:2f:cf:0b' 'be:05:40:56:af:35'\n",
      " 'be:43:b8:26:a5:9e' 'c6:59:24:98:5d:4b' 'c6:e0:92:6b:61:09'\n",
      " 'ca:9a:c1:84:bf:6d' 'ca:de:d2:be:ba:1a' 'ce:8a:f7:cc:bc:ba'\n",
      " 'd2:46:92:96:89:55' 'd2:84:86:c4:4d:e3' 'd2:c4:88:e3:23:70'\n",
      " 'd2:e8:4e:73:71:ab' 'd6:a5:b5:2d:62:5b' 'd6:bb:96:fb:eb:32'\n",
      " 'd6:eb:d0:ef:5c:ec' 'da:41:df:d7:34:d7' 'da:5f:73:c1:ec:43'\n",
      " 'da:b6:c3:fa:48:12' 'da:d8:23:79:da:25' 'de:81:f9:b5:80:46'\n",
      " 'de:b6:f1:0c:e7:ff' 'e2:05:e4:4f:fd:94' 'e2:65:c2:f0:63:60'\n",
      " 'e6:05:ff:97:a1:ef' 'e6:60:55:7b:db:39' 'ea:d6:ac:26:11:1c'\n",
      " 'ea:ff:a2:e9:10:ad' 'ee:c4:e2:97:4c:21' 'f2:5a:4c:89:78:f9'\n",
      " 'f2:92:ec:65:b1:21' 'f6:02:4a:2a:55:64' 'f6:03:da:61:b9:c4'\n",
      " 'f6:14:48:57:4e:c3' 'f6:61:e8:74:79:90' 'f6:90:cb:29:ed:1b'\n",
      " 'f6:d0:02:25:77:3b' 'f6:f8:8d:83:3c:a3' 'fa:44:c9:e6:30:71'\n",
      " 'fa:57:8f:59:f4:bb' 'fa:6e:0b:1c:09:ce' 'fa:9e:cc:a2:23:6d'\n",
      " 'fe:0c:fb:68:17:02' 'fe:22:29:f4:b5:ac' 'fe:79:1d:49:3b:fb'\n",
      " 'fe:8b:00:75:88:22']\n",
      "Encoded Labels: 0         95\n",
      "1         52\n",
      "2         44\n",
      "3         61\n",
      "4         43\n",
      "          ..\n",
      "914327    52\n",
      "914328    61\n",
      "914329    43\n",
      "914330    76\n",
      "914331    43\n",
      "Name: D_MAC, Length: 914332, dtype: object\n",
      "Unique Classes: ['0.0.139.166' '0.0.141.91' '0.0.2.186' ... '99.99.79.225' '99.99.79.80'\n",
      " '99.99.96.135']\n",
      "Encoded Labels: 0         357824\n",
      "1         322577\n",
      "2         207946\n",
      "3           3333\n",
      "4         105254\n",
      "           ...  \n",
      "914327     39788\n",
      "914328      3352\n",
      "914329    285844\n",
      "914330      3349\n",
      "914331     35897\n",
      "Name: SIP, Length: 914332, dtype: object\n",
      "Unique Classes: ['10.0.0.1' '10.0.0.10' '10.0.0.11' '10.0.0.12' '10.0.0.13' '10.0.0.14'\n",
      " '10.0.0.15' '10.0.0.16' '10.0.0.17' '10.0.0.18' '10.0.0.19' '10.0.0.2'\n",
      " '10.0.0.20' '10.0.0.21' '10.0.0.22' '10.0.0.23' '10.0.0.3' '10.0.0.4'\n",
      " '10.0.0.5' '10.0.0.6' '10.0.0.7' '10.0.0.8' '10.0.0.9']\n",
      "Encoded Labels: 0          3\n",
      "1          0\n",
      "2          4\n",
      "3          7\n",
      "4          2\n",
      "          ..\n",
      "914327     0\n",
      "914328     7\n",
      "914329     2\n",
      "914330    16\n",
      "914331     2\n",
      "Name: DIP, Length: 914332, dtype: object\n",
      "Unique Classes: ['attack' 'normal']\n",
      "Encoded Labels: 0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "914327    0\n",
      "914328    0\n",
      "914329    0\n",
      "914330    0\n",
      "914331    0\n",
      "Name: label, Length: 914332, dtype: object\n",
      "Unique Classes: ['Bhttp_flood.pcap' 'Bicmp_flood.pcap' 'Bmqtt_udp_flood.pcap'\n",
      " 'Btcp_flood.pcap' 'Budp_flood.pcap' 'Hicmp_flood.pcap' 'Htcp_flood.pcap'\n",
      " 'Hudp_flood.pcap' 'hmqtt_TcpSyn_flood.pcap' 'mqtt_publish_flood1.pcap'\n",
      " 'normal']\n",
      "Encoded Labels: 0         7\n",
      "1         5\n",
      "2         6\n",
      "3         3\n",
      "4         8\n",
      "         ..\n",
      "914327    5\n",
      "914328    3\n",
      "914329    8\n",
      "914330    4\n",
      "914331    8\n",
      "Name: type, Length: 914332, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X=encod(X)\n",
    "EY=encod(Y)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)\n",
    "# X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S_MAC', 'D_MAC', 'FPT', 'LPT', 'SIT', 'STT', 'SIP', 'DIP', 'SPort',\n",
       "       'DPort', 'label', 'type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EY.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack Identification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled.iloc[:,:],EY.iloc[:,-2].astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = LogisticRegression()\n",
    "# kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "# clf = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "def evaluate_features(clf,features,X_train,y_train,y_test):\n",
    "    clf.fit(X_train.iloc[:,features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Perform wrapper feature selection\n",
    "num_features = X_train.shape[1]\n",
    "selected_features = [40,59]\n",
    "best_accuracy = 0\n",
    "\n",
    "for _ in range(num_features):\n",
    "    best_feature = None\n",
    "    for feature in range(num_features):\n",
    "        if feature not in selected_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            #print(current_features)\n",
    "            accuracy = evaluate_features(clf,current_features,X_train,y_train,y_test)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_feature = feature\n",
    "    if best_feature is not None:\n",
    "        selected_features.append(best_feature)\n",
    "        print(f\"Selected feature {best_feature}, Accuracy: {best_accuracy:.5f}\")\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=X_train_scaled.iloc[:,selected_features].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FIN_FC', 'TCPWS_Mean', 'RTT', 'FAMax', 'DACount', 'FAPS', 'TCP_HD',\n",
       "       'HTTPRM_L', 'Proto', 'SYN_FC', 'D_type', 'BytesPS', 'TCPWS_Sum',\n",
       "       'HL_mean', 'PEntropy', 'FBPP', 'FD', 'FAStd', 'FEntropy', 'FlowStd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func for missing values imputation, encoding, and normalization\n",
    "\n",
    "def encod(data):\n",
    "  from sklearn import preprocessing\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "  try:\n",
    "    n=data.shape[1]\n",
    "    for i in range(n):\n",
    "      if data.iloc[:,i].dtype == 'object':\n",
    "\n",
    "        data.iloc[:,i]= label_encoder.fit_transform(data.iloc[:,i])\n",
    "        unique_classes = label_encoder.classes_\n",
    "        print(\"Unique Classes:\", unique_classes)\n",
    "        print(\"Encoded Labels:\", data.iloc[:,i])\n",
    "    return data\n",
    "  except:\n",
    "    if data.dtype == 'object':\n",
    "      n=len(data)\n",
    "      data= label_encoder.fit_transform(data)\n",
    "    return data\n",
    "  \n",
    "def normalize_scale(X):\n",
    "  m= X.values #returns a numpy array\n",
    "  cols_name = X.columns\n",
    "  scaler = preprocessing.MinMaxScaler()\n",
    "  x_scaled = scaler.fit_transform(m)\n",
    "  #scaler.transform(X) for scaling using the previous weights\n",
    "  Scale_X = pd.DataFrame(x_scaled,columns = cols_name)\n",
    "  return Scale_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=['FIN_FC', 'TCPWS_Mean'] # device classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=['FIN_FC', 'TCPWS_Mean', 'RTT', 'FAMax', 'DACount', 'FAPS', 'TCP_HD',\n",
    "       'HTTPRM_L', 'Proto', 'SYN_FC', 'D_type', 'BytesPS', 'TCPWS_Sum',\n",
    "       'HL_mean', 'PEntropy', 'FBPP', 'FD', 'FAStd', 'FEntropy', 'FlowStd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=['RTT', 'FIN_FC', 'SYN_FC', 'FAMax', 'DACount', 'FAPS', 'TCP_HD',\n",
    "       'Proto', 'HTTPRM_L', 'BytesPS', 'PEntropy', 'FD', 'FEntropy', 'FBPP',\n",
    "       'BackwardPC', 'FAMin'] # attack detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes: ['CD' 'IoT' 'NU']\n",
      "Encoded Labels: 0         2\n",
      "1         2\n",
      "2         2\n",
      "3         2\n",
      "4         1\n",
      "         ..\n",
      "914327    2\n",
      "914328    2\n",
      "914329    1\n",
      "914330    2\n",
      "914331    1\n",
      "Name: D_type, Length: 914332, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)\n",
    "X=data[b]\n",
    "X=encod(X)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)\n",
    "\n",
    "EY=encod(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\Install\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97039\n",
      "Precision: 0.96953\n",
      "Recall: 0.97039\n",
      "F1-score: 0.96907\n",
      "MCC: 0.82276\n",
      "Average Prediction Time: 11.9008 ms\n"
     ]
    }
   ],
   "source": [
    "# Attack detection + D_type\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\Install\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67554\n",
      "Precision: 0.74005\n",
      "Recall: 0.67554\n",
      "F1-score: 0.60714\n",
      "MCC: 0.36446\n",
      "Average Prediction Time: 13.3396 ms\n"
     ]
    }
   ],
   "source": [
    "# Device Identification\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\Install\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96547\n",
      "Precision: 0.96447\n",
      "Recall: 0.96547\n",
      "F1-score: 0.96334\n",
      "MCC: 0.79014\n",
      "Average Prediction Time: 11.4203 ms\n"
     ]
    }
   ],
   "source": [
    "# Attack Identification\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled.iloc[:,selected_features],EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import PcapReader, IP, TCP, UDP, Raw\n",
    "from scapy.layers.l2 import Ether\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def extract_flow_features(pcap_file, time_interval=1):\n",
    "    flows = defaultdict(list)\n",
    "    features = []\n",
    "\n",
    "    with PcapReader(pcap_file) as packets:\n",
    "    \n",
    "        current_time = 0\n",
    "        for packet in packets:\n",
    "            if IP in packet:\n",
    "                mac_src=packet[Ether].src\n",
    "                mac_dst=packet[Ether].dst\n",
    "                ip_src = packet[IP].src\n",
    "                ip_dst = packet[IP].dst\n",
    "                timestamp = packet.time\n",
    "                if timestamp - current_time >= time_interval:\n",
    "                    features.extend(process_flows(flows))\n",
    "                    flows.clear()\n",
    "                    current_time = timestamp\n",
    "                if TCP in packet:\n",
    "                    flags = packet[TCP].flags\n",
    "                    header_length = len(packet[TCP])\n",
    "                    tcp_window_size = packet[TCP].window\n",
    "                    tcp_options = packet[TCP].options if packet[TCP].options else []\n",
    "                elif UDP in packet:\n",
    "                    flags = 0\n",
    "                    header_length = len(packet[UDP])\n",
    "                    tcp_window_size = 0\n",
    "                    tcp_options = []\n",
    "                else:\n",
    "                    tcp_options = []\n",
    "                flow_key = (mac_src,mac_dst,ip_src, ip_dst)\n",
    "                flows[flow_key].append((timestamp, len(packet), flags, header_length, tcp_window_size, tcp_options, packet))\n",
    "        features.extend(process_flows(flows))\n",
    "    return features\n",
    "\n",
    "def process_flows(flows):\n",
    "    features = []\n",
    "\n",
    "    for flow_key, packets in flows.items():\n",
    "        mac_src,mac_dst,ip_src, ip_dst = flow_key\n",
    "        timestamps, lengths, flags, header_lengths, tcp_window_sizes, tcp_options, raw_packets = zip(*packets)\n",
    "        flow_duration = max(timestamps) - min(timestamps)\n",
    "        total_packets = len(packets)\n",
    "        total_bytes = sum(lengths)\n",
    "        flow_std = np.std(lengths)\n",
    "        packet_lengths = lengths       \n",
    "        iat = np.diff(timestamps)\n",
    "        forward_iat = np.diff([ts for ts, l, f, h, w, to, rp in packets if rp[IP].src == ip_src])\n",
    "        fin_flag_count = sum(1 for f in flags if f & 0x01)\n",
    "        psh_flag_count = sum(1 for f in flags if f & 0x08)\n",
    "        flow_active_min = np.min(np.array(iat, dtype=float)) if len(iat) > 0 else 0\n",
    "        flow_active_max = np.max(np.array(iat, dtype=float)) if len(iat) > 0 else 0\n",
    "        flow_idle_times = [iat[i] - iat[i-1] for i in range(1, len(iat))]\n",
    "        flow_idle_mean = np.mean(np.array(flow_idle_times, dtype=float)) if len(flow_idle_times) > 0 else 0\n",
    "        flow_idle_min = np.min(np.array(flow_idle_times, dtype=float)) if len(flow_idle_times) > 0 else 0\n",
    "        flow_idle_std = np.std(np.array(flow_idle_times, dtype=float)) if len(flow_idle_times) > 0 else 0\n",
    "        rtt = sum([packet[TCP].ack for packet in raw_packets if TCP in packet and 'A' in packet[TCP].flags]) / total_packets if total_packets > 0 else 0\n",
    "        retransmission_count = sum(1 for packet in raw_packets if TCP in packet and packet[TCP].flags == 'R')\n",
    "        flow_entropy = -np.sum([p / total_packets * np.log2(p / total_packets) for p in packet_lengths])\n",
    "        payloads = [len(packet[Raw].load) for packet in raw_packets if Raw in packet]\n",
    "        payload_length = np.sum(payloads)\n",
    "        payload_entropy = -np.sum([p / payload_length * np.log2(p / payload_length) for p in payloads]) if payload_length > 0 else 0\n",
    "        try:\n",
    "            tcp_window_size_sum=sum(tcp_window_sizes) #\n",
    "        except:\n",
    "            tcp_window_size_sum=None\n",
    "\n",
    "        try:\n",
    "            tcp_window_size_mean=np.mean(tcp_window_sizes) #\n",
    "        except:\n",
    "            tcp_window_size_mean=None\n",
    "           \n",
    "        \n",
    "        features.append({\n",
    "            \"S_MAC\":mac_src,                            # Source MAC\n",
    "            \"D_MAC\":mac_dst,                            # Destination MAC\n",
    "            \"FD\": flow_duration,                        # Flow Duration\n",
    "            \"FAMin\": flow_active_min,                   # Flow Active Min\n",
    "            \"FAMax\": flow_active_max,                   # Flow Active Max\n",
    "            \"FIMean\": flow_idle_mean,                   # Flow Idle Mean\n",
    "            \"FIMin\": flow_idle_min,                     # Flow Idle Min\n",
    "            \"FIStd\": flow_idle_std,                     # Flow Idle Std\n",
    "            \"TBytes\": total_bytes,                      # Total Bytes\n",
    "            \"FlowStd\": flow_std,                        # Flow Standard Deviation\n",
    "            \"SIP\": ip_src,                              # Source IP\n",
    "            \"DIP\": ip_dst,                              # Destination IP\n",
    "            \"RTT\": rtt,                                 # Round Trip Time\n",
    "            \"FIN_FC\":fin_flag_count,                    # FIN Flag Count\n",
    "            \"PSH_FC\":psh_flag_count,                    # PSH Flag Count\n",
    "            \"RCount\": retransmission_count,             # Retransmission Count\n",
    "            \"FEntropy\": flow_entropy,                   # Flow Entropy\n",
    "            \"PIA_Var\": np.var(np.array(iat, dtype=float)) if len(iat) > 0 else 0, #Packet Inter-Arrival Variance\n",
    "            \"PL\": payload_length,                       # Payload Length\n",
    "            \"PEntropy\": payload_entropy,                # Payload Entropy\n",
    "            \"FIPD_Var\": np.var(np.array(forward_iat, dtype=float)) if len(forward_iat) > 0 else 0, # Forward Inter-Packet Delay Variance\n",
    "            \"TCPWS_Sum\": tcp_window_size_sum,           # TCP Window Size Sum\n",
    "            \"TCPWS_Mean\": tcp_window_size_mean         # TCP Window Size Mean\n",
    "        })\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sniffing on Ethernet...Sniffing on Ethernet 3...\n",
      "\n",
      "Captured 23 packets on EthernetCaptured 0 packets on Ethernet 3\n",
      "\n",
      "Total packets captured from all interfaces: 23\n"
     ]
    }
   ],
   "source": [
    "from scapy.all import sniff\n",
    "import threading\n",
    "\n",
    "# Define multiple interfaces (Change based on your system)\n",
    "interfaces = [\"Ethernet\", \"Ethernet 3\"]  # Example: \"eth0\" for Ethernet, \"wlan0\" for Wi-Fi\n",
    "\n",
    "# Shared variable to store all packets\n",
    "all_packets = []\n",
    "\n",
    "# Function to sniff packets on a specific interface\n",
    "def sniff_packets(interface):\n",
    "    global all_packets\n",
    "    print(f\"Sniffing on {interface}...\")\n",
    "    \n",
    "    # Capture packets for 5 seconds\n",
    "    packets = sniff(iface=interface, timeout=5)\n",
    "    \n",
    "    # Append captured packets to the global list\n",
    "    all_packets.extend(packets)\n",
    "    \n",
    "    print(f\"Captured {len(packets)} packets on {interface}\")\n",
    "\n",
    "# Start sniffing on multiple interfaces using threads\n",
    "threads = []\n",
    "for iface in interfaces:\n",
    "    t = threading.Thread(target=sniff_packets, args=(iface,))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# Print final packet count\n",
    "print(f\"Total packets captured from all interfaces: {len(all_packets)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Ether  dst=cc:96:e5:2d:42:ff src=94:f3:92:96:80:e8 type=IPv4 |<IP  version=4 ihl=5 tos=0x0 len=40 id=7176 flags=DF frag=0 ttl=64 proto=tcp chksum=0xfaf7 src=52.168.117.169 dst=10.118.111.9 |<TCP  sport=https dport=53127 seq=230120682 ack=3683749125 dataofs=5 reserved=0 flags=A window=616 chksum=0xe520 urgptr=0 |<Padding  load='\\x00\\x00\\x00\\x00\\x00\\x00' |>>>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_packets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Windows IP Configuration\n",
      "\n",
      "\n",
      "Ethernet adapter Ethernet:\n",
      "\n",
      "   Connection-specific DNS Suffix  . : \n",
      "   Link-local IPv6 Address . . . . . : fe80::82e:6420:2572:b111%18\n",
      "   IPv4 Address. . . . . . . . . . . : 10.118.111.9\n",
      "   Subnet Mask . . . . . . . . . . . : 255.255.0.0\n",
      "   Default Gateway . . . . . . . . . : 10.118.0.254\n",
      "\n",
      "Ethernet adapter Ethernet 3:\n",
      "\n",
      "   Connection-specific DNS Suffix  . : \n",
      "   Link-local IPv6 Address . . . . . : fe80::4381:2354:16db:d14a%16\n",
      "   IPv4 Address. . . . . . . . . . . : 192.168.56.1\n",
      "   Subnet Mask . . . . . . . . . . . : 255.255.255.0\n",
      "   Default Gateway . . . . . . . . . : \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import platform\n",
    "\n",
    "# Define command based on OS\n",
    "if platform.system() == \"Windows\":\n",
    "    command = \"ipconfig\"  # Windows CMD command\n",
    "else:\n",
    "    command = \"ls -l\"  # Linux Terminal command\n",
    "\n",
    "# Run the command\n",
    "result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(result.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
