{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "attack    824359\n",
       "normal     89973\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D_type\n",
       "NU     536450\n",
       "IoT    345875\n",
       "CD      32007\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['D_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "Hudp_flood.pcap             89973\n",
       "Hicmp_flood.pcap            89973\n",
       "Htcp_flood.pcap             89973\n",
       "Btcp_flood.pcap             89973\n",
       "hmqtt_TcpSyn_flood.pcap     89973\n",
       "normal                      89973\n",
       "mqtt_publish_flood1.pcap    89973\n",
       "Budp_flood.pcap             89973\n",
       "Bhttp_flood.pcap            89973\n",
       "Bmqtt_udp_flood.pcap        89973\n",
       "Bicmp_flood.pcap            14602\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S_MAC', 'D_MAC', 'FPT', 'LPT', 'FD', 'FAMin', 'FAMean', 'FAMax',\n",
       "       'FAStd', 'FIMean', 'FIMin', 'FIMax', 'FIStd', 'DSCP_C', 'ECN_C',\n",
       "       'TPackets', 'TBytes', 'SBytes', 'DBytes', 'PLM', 'FI', 'FIAT', 'BIAT',\n",
       "       'ForwardPC', 'BackwardPC', 'FlowR', 'FlowStd', 'FlowV', 'FH_M', 'FAPS',\n",
       "       'BAPS', 'FBPP', 'FFD', 'Proto', 'SIP', 'DIP', 'SPort', 'DPort',\n",
       "       'SDuration', 'SPC', 'SBCount', 'BytesPS', 'PacketsPS', 'RTT', 'HL_Sum',\n",
       "       'HL_Mode', 'HL_mean', 'SYN_FC', 'FIN_FC', 'RST_FC', 'PSH_FC', 'TCP_HD',\n",
       "       'RCount', 'DACount', 'MPackets', 'FThroughput', 'BThroughput',\n",
       "       'FJitter', 'BJitter', 'FBurst', 'FEntropy', 'PIA_Var', 'PL', 'PEntropy',\n",
       "       'SIT', 'STT', 'FIPD_Var', 'BIPD_Var', 'TCPWS_Sum', 'TCPWS_Mean',\n",
       "       'TCPWS_Mode', 'HTTPRM_L', 'HTTPRM_UL', 'HTTP_SCL', 'HTTP_SCUL:',\n",
       "       'label', 'type', 'D_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_Features=['S_MAC',\n",
    "'D_MAC',\n",
    "'FPT',\n",
    "'LPT',\n",
    "'SIT',\n",
    "'STT',\n",
    "'SIP',\n",
    "'DIP',\n",
    "'SPort',\n",
    "'DPort',\n",
    "'label',\n",
    "'type',\n",
    "'D_type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data[ID_Features]\n",
    "X=data.drop(ID_Features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X:\n",
    "      if X[i].dtype == 'object':\n",
    "            print(i)\n",
    "# no categorical data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.25.2'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func for missing values imputation, encoding, and normalization\n",
    "\n",
    "def encod(data):\n",
    "  from sklearn import preprocessing\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "  try:\n",
    "    n=data.shape[1]\n",
    "    for i in range(n):\n",
    "      if data.iloc[:,i].dtype == 'object':\n",
    "\n",
    "        data.iloc[:,i]= label_encoder.fit_transform(data.iloc[:,i])\n",
    "        unique_classes = label_encoder.classes_\n",
    "        print(\"Unique Classes:\", unique_classes)\n",
    "        print(\"Encoded Labels:\", data.iloc[:,i])\n",
    "    return data\n",
    "  except:\n",
    "    if data.dtype == 'object':\n",
    "      n=len(data)\n",
    "      data= label_encoder.fit_transform(data)\n",
    "    return data\n",
    "  \n",
    "\n",
    "\n",
    "def normalize_scale(X):\n",
    "  m= X.values #returns a numpy array\n",
    "  cols_name = X.columns\n",
    "  scaler = preprocessing.MinMaxScaler()\n",
    "  x_scaled = scaler.fit_transform(m)\n",
    "  #scaler.transform(X) for scaling using the previous weights\n",
    "  Scale_X = pd.DataFrame(x_scaled,columns = cols_name)\n",
    "  return Scale_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=encod(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9236\\2999448690.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(Y['D_type'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "D_type\n",
       "NU     536450\n",
       "IoT    345875\n",
       "CD      32007\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(Y['D_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "EY=encod(Y['D_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9236\\1294995040.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(EY)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    536450\n",
       "1    345875\n",
       "0     32007\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(EY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 2, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FD</th>\n",
       "      <th>FAMin</th>\n",
       "      <th>FAMean</th>\n",
       "      <th>FAMax</th>\n",
       "      <th>FAStd</th>\n",
       "      <th>FIMean</th>\n",
       "      <th>FIMin</th>\n",
       "      <th>FIMax</th>\n",
       "      <th>FIStd</th>\n",
       "      <th>DSCP_C</th>\n",
       "      <th>...</th>\n",
       "      <th>PEntropy</th>\n",
       "      <th>FIPD_Var</th>\n",
       "      <th>BIPD_Var</th>\n",
       "      <th>TCPWS_Sum</th>\n",
       "      <th>TCPWS_Mean</th>\n",
       "      <th>TCPWS_Mode</th>\n",
       "      <th>HTTPRM_L</th>\n",
       "      <th>HTTPRM_UL</th>\n",
       "      <th>HTTP_SCL</th>\n",
       "      <th>HTTP_SCUL:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.094291</td>\n",
       "      <td>0.094291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914327</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914328</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.094291</td>\n",
       "      <td>0.094291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914329</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914330</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914331</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.500227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>914332 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FD     FAMin    FAMean     FAMax  FAStd    FIMean     FIMin  \\\n",
       "0       0.0  0.053732  0.000638  0.000638    0.0  0.500227  0.500227   \n",
       "1       0.0  0.053732  0.000638  0.000638    0.0  0.500227  0.500227   \n",
       "2       0.0  0.053732  0.000638  0.000638    0.0  0.500227  0.500227   \n",
       "3       0.0  0.053732  0.000638  0.000638    0.0  0.500227  0.500227   \n",
       "4       0.0  0.053732  0.000638  0.000638    0.0  0.500227  0.500227   \n",
       "...     ...       ...       ...       ...    ...       ...       ...   \n",
       "914327  0.0  0.053732  0.000638  0.000638    0.0  0.500227  0.500227   \n",
       "914328  0.0  0.053732  0.000638  0.000638    0.0  0.500227  0.500227   \n",
       "914329  0.0  0.053732  0.000638  0.000638    0.0  0.500227  0.500227   \n",
       "914330  0.0  0.053732  0.000638  0.000638    0.0  0.500227  0.500227   \n",
       "914331  0.0  0.053732  0.000638  0.000638    0.0  0.500227  0.500227   \n",
       "\n",
       "           FIMax  FIStd  DSCP_C  ...  PEntropy  FIPD_Var  BIPD_Var  TCPWS_Sum  \\\n",
       "0       0.500227    0.0     0.0  ...       0.0       0.0       0.0   0.000000   \n",
       "1       0.500227    0.0     0.0  ...       0.0       0.0       0.0   0.000000   \n",
       "2       0.500227    0.0     0.0  ...       0.0       0.0       0.0   0.000287   \n",
       "3       0.500227    0.0     0.0  ...       0.0       0.0       0.0   0.002295   \n",
       "4       0.500227    0.0     0.0  ...       0.0       0.0       0.0   0.000287   \n",
       "...          ...    ...     ...  ...       ...       ...       ...        ...   \n",
       "914327  0.500227    0.0     0.0  ...       0.0       0.0       0.0   0.000000   \n",
       "914328  0.500227    0.0     0.0  ...       0.0       0.0       0.0   0.002295   \n",
       "914329  0.500227    0.0     0.0  ...       0.0       0.0       0.0   0.000287   \n",
       "914330  0.500227    0.0     0.0  ...       0.0       0.0       0.0   0.000000   \n",
       "914331  0.500227    0.0     0.0  ...       0.0       0.0       0.0   0.000287   \n",
       "\n",
       "        TCPWS_Mean  TCPWS_Mode  HTTPRM_L  HTTPRM_UL  HTTP_SCL  HTTP_SCUL:  \n",
       "0         0.000000    0.000000       0.0        0.0       0.0         0.0  \n",
       "1         0.000000    0.000000       0.0        0.0       0.0         0.0  \n",
       "2         0.011786    0.011786       0.0        0.0       0.0         0.0  \n",
       "3         0.094291    0.094291       0.0        0.0       0.0         0.0  \n",
       "4         0.011786    0.011786       0.0        0.0       0.0         0.0  \n",
       "...            ...         ...       ...        ...       ...         ...  \n",
       "914327    0.000000    0.000000       0.0        0.0       0.0         0.0  \n",
       "914328    0.094291    0.094291       0.0        0.0       0.0         0.0  \n",
       "914329    0.011786    0.011786       0.0        0.0       0.0         0.0  \n",
       "914330    0.000000    0.000000       0.0        0.0       0.0         0.0  \n",
       "914331    0.011786    0.011786       0.0        0.0       0.0         0.0  \n",
       "\n",
       "[914332 rows x 65 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature 40, Accuracy: 0.6686\n",
      "Selected feature 59, Accuracy: 0.6743\n",
      "Selected feature 35, Accuracy: 0.6797\n",
      "Selected feature 55, Accuracy: 0.6853\n",
      "Selected feature 0, Accuracy: 0.6864\n",
      "Selected feature 58, Accuracy: 0.6882\n",
      "Selected feature 45, Accuracy: 0.6898\n",
      "Selected feature 43, Accuracy: 0.6902\n",
      "Selected feature 60, Accuracy: 0.6902\n",
      "Selected feature 22, Accuracy: 0.6930\n",
      "Selected feature None, Accuracy: 0.6930\n",
      "Selected features: [40, 59, 35, 55, 0, 58, 45, 43, 60, 22]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# clf = RandomForestClassifier(random_state=42)\n",
    "clf=GaussianNB()\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "def evaluate_features(clf,features,X_train,y_train,y_test):\n",
    "    clf.fit(X_train.iloc[:,features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Perform wrapper feature selection\n",
    "num_features = X_train.shape[1]\n",
    "selected_features = []\n",
    "best_accuracy = 0\n",
    "\n",
    "for _ in range(num_features):\n",
    "    best_feature = None\n",
    "    for feature in range(num_features):\n",
    "        if feature not in selected_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            #print(current_features)\n",
    "            accuracy = evaluate_features(clf,current_features,X_train,y_train,y_test)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_feature = feature\n",
    "    if best_feature is not None:\n",
    "        selected_features.append(best_feature)\n",
    "        print(f\"Selected feature {best_feature}, Accuracy: {best_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(f\"Selected feature {best_feature}, Accuracy: {best_accuracy:.4f}\")\n",
    "        break\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FIN_FC', 'TCPWS_Mean', 'RTT', 'PEntropy', 'FD', 'TCPWS_Sum', 'DACount',\n",
       "       'TCP_HD', 'TCPWS_Mode', 'FlowStd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X.iloc[:,selected_features].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'FIN_FC', 'TCPWS_Mean', 'RTT', 'PEntropy', 'FD', 'TCPWS_Sum', 'DACount',\n",
    "       'TCP_HD', 'TCPWS_Mode', 'FlowStd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB\n",
    "a=['FAPS', 'TCPWS_Sum', 'Proto', 'BytesPS', 'FThroughput', 'FAMin',\n",
    "       'RCount', 'TCPWS_Mode', 'DSCP_C', 'TCPWS_Mean'] # attack detection\n",
    "\n",
    "b=['D_type', 'FAMax', 'TCP_HD', 'FIN_FC', 'RTT', 'SYN_FC', 'DSCP_C',\n",
    "       'Proto', 'BIPD_Var', 'FEntropy', 'RCount', 'ECN_C', 'TCPWS_Mean']\n",
    "\n",
    "c=['FIN_FC', 'TCPWS_Mean', 'RTT', 'PEntropy', 'FD', 'TCPWS_Sum', 'DACount',\n",
    "       'TCP_HD', 'TCPWS_Mode', 'FlowStd'] # device type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)\n",
    "X=data[c]\n",
    "X=encod(X)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)\n",
    "\n",
    "EY=encod(data['D_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98720\n",
      "Precision: 0.98743\n",
      "Recall: 0.98720\n",
      "F1-score: 0.98729\n",
      "MCC: 0.92878\n",
      "Average Prediction Time: 52.8973 ms\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = GaussianNB()\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)\n",
    "ID_Features=['S_MAC',\n",
    "'D_MAC',\n",
    "'FPT',\n",
    "'LPT',\n",
    "'SIT',\n",
    "'STT',\n",
    "'SIP',\n",
    "'DIP',\n",
    "'SPort',\n",
    "'DPort',\n",
    "'label',\n",
    "'type']\n",
    "#, 'D_type']\n",
    "\n",
    "def encod(data):\n",
    "  from sklearn import preprocessing\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "  try:\n",
    "    n=data.shape[1]\n",
    "    for i in range(n):\n",
    "      if data.iloc[:,i].dtype == 'object':\n",
    "\n",
    "        data.iloc[:,i]= label_encoder.fit_transform(data.iloc[:,i])\n",
    "        unique_classes = label_encoder.classes_\n",
    "        print(\"Unique Classes:\", unique_classes)\n",
    "        print(\"Encoded Labels:\", data.iloc[:,i])\n",
    "    return data\n",
    "  except:\n",
    "    if data.dtype == 'object':\n",
    "      n=len(data)\n",
    "      data= label_encoder.fit_transform(data)\n",
    "    return data\n",
    "  \n",
    "\n",
    "\n",
    "def normalize_scale(X):\n",
    "  m= X.values #returns a numpy array\n",
    "  cols_name = X.columns\n",
    "  scaler = preprocessing.MinMaxScaler()\n",
    "  x_scaled = scaler.fit_transform(m)\n",
    "  #scaler.transform(X) for scaling using the previous weights\n",
    "  Scale_X = pd.DataFrame(x_scaled,columns = cols_name)\n",
    "  return Scale_X\n",
    "\n",
    "Y=data[ID_Features]\n",
    "X=data.drop(ID_Features,axis=1)\n",
    "for i in X:\n",
    "      if X[i].dtype == 'object':\n",
    "            print(i)\n",
    "# no categorical data type\n",
    "X=encod(X)\n",
    "EY=encod(Y['label'])\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func for missing values imputation, encoding, and normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_type\n",
      "Unique Classes: ['CD' 'IoT' 'NU']\n",
      "Encoded Labels: 0         2\n",
      "1         2\n",
      "2         2\n",
      "3         2\n",
      "4         1\n",
      "         ..\n",
      "914327    2\n",
      "914328    2\n",
      "914329    1\n",
      "914330    2\n",
      "914331    1\n",
      "Name: D_type, Length: 914332, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature 12, Accuracy: 0.99997\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# clf = RandomForestClassifier(random_state=42)\n",
    "clf=ExtraTreesClassifier()\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "def evaluate_features(clf,features,X_train,y_train,y_test):\n",
    "    clf.fit(X_train.iloc[:,features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Perform wrapper feature selection\n",
    "num_features = X_train.shape[1]\n",
    "selected_features = [52,58,35,65,40,21,22,42,24,19,15,51,27,9,10,12]\n",
    "best_accuracy = 0\n",
    "\n",
    "for _ in range(num_features):\n",
    "    best_feature = None\n",
    "    for feature in range(num_features):\n",
    "        if feature not in selected_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            #print(current_features)\n",
    "            accuracy = evaluate_features(clf,current_features,X_train,y_train,y_test)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_feature = feature\n",
    "    if best_feature is not None:\n",
    "        selected_features.append(best_feature)\n",
    "        print(f\"Selected feature {best_feature}, Accuracy: {best_accuracy:.5f}\")\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SF= X_train_scaled.iloc[:,[52,58,35,65,40,21,22,42,24,19,15,51,27,9,10,12]].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_type\n",
      "Unique Classes: ['CD' 'IoT' 'NU']\n",
      "Encoded Labels: 0         2\n",
      "1         2\n",
      "2         2\n",
      "3         2\n",
      "4         1\n",
      "         ..\n",
      "914327    2\n",
      "914328    2\n",
      "914329    1\n",
      "914330    2\n",
      "914331    1\n",
      "Name: D_type, Length: 914332, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)\n",
    "ID_Features=['S_MAC',\n",
    "'D_MAC',\n",
    "'FPT',\n",
    "'LPT',\n",
    "'SIT',\n",
    "'STT',\n",
    "'SIP',\n",
    "'DIP',\n",
    "'SPort',\n",
    "'DPort',\n",
    "'label',\n",
    "'type']\n",
    "#, 'D_type']\n",
    "\n",
    "def encod(data):\n",
    "  from sklearn import preprocessing\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "  try:\n",
    "    n=data.shape[1]\n",
    "    for i in range(n):\n",
    "      if data.iloc[:,i].dtype == 'object':\n",
    "\n",
    "        data.iloc[:,i]= label_encoder.fit_transform(data.iloc[:,i])\n",
    "        unique_classes = label_encoder.classes_\n",
    "        print(\"Unique Classes:\", unique_classes)\n",
    "        print(\"Encoded Labels:\", data.iloc[:,i])\n",
    "    return data\n",
    "  except:\n",
    "    if data.dtype == 'object':\n",
    "      n=len(data)\n",
    "      data= label_encoder.fit_transform(data)\n",
    "    return data\n",
    "  \n",
    "\n",
    "\n",
    "def normalize_scale(X):\n",
    "  m= X.values #returns a numpy array\n",
    "  cols_name = X.columns\n",
    "  scaler = preprocessing.MinMaxScaler()\n",
    "  x_scaled = scaler.fit_transform(m)\n",
    "  #scaler.transform(X) for scaling using the previous weights\n",
    "  Scale_X = pd.DataFrame(x_scaled,columns = cols_name)\n",
    "  return Scale_X\n",
    "\n",
    "Y=data[ID_Features]\n",
    "X=data[SF]\n",
    "for i in X:\n",
    "      if X[i].dtype == 'object':\n",
    "            print(i)\n",
    "# no categorical data type\n",
    "X=encod(X)\n",
    "EY=encod(Y['label'])\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FEntropy', 'TCPWS_Sum', 'RTT', 'D_type', 'FIN_FC', 'FlowR', 'FlowStd',\n",
       "       'PSH_FC', 'FH_M', 'ForwardPC', 'PLM', 'FBurst', 'FBPP', 'DSCP_C',\n",
       "       'ECN_C', 'TBytes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99995\n",
      "Precision: 0.99995\n",
      "Recall: 0.99995\n",
      "F1-score: 0.99995\n",
      "MCC: 0.99972\n",
      "Average Prediction Time: 1779.8788 ms\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY.astype('int'), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = ExtraTreesClassifier()\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# joblib.dump(scaler, \"device_classification_scaler.pkl\")\n",
    "\n",
    "DCscaler = joblib.load(\"Attack_Identification_scaler.pkl\")\n",
    "XO = DCscaler.transform(data[b])\n",
    "\n",
    "# X_test_scaled\n",
    "# Load the saved model\n",
    "rf_loaded = joblib.load(\"AttackDetection_model.pkl\")\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "# X_test = np.random.rand(1, 10)\n",
    "pred = rf_loaded.predict(XO)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Final_balanced_dataset.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[['FIN_FC', 'TCPWS_Mean', 'RTT', 'PEntropy', 'FD', 'TCPWS_Sum', 'DACount',\n",
    "       'TCP_HD', 'TCPWS_Mode', 'FlowStd']]\n",
    "Y=data['D_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encod(data):\n",
    "  from sklearn import preprocessing\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "  try:\n",
    "    n=data.shape[1]\n",
    "    for i in range(n):\n",
    "      if data.iloc[:,i].dtype == 'object':\n",
    "\n",
    "        data.iloc[:,i]= label_encoder.fit_transform(data.iloc[:,i])\n",
    "        unique_classes = label_encoder.classes_\n",
    "        print(\"Unique Classes:\", unique_classes)\n",
    "        print(\"Encoded Labels:\", data.iloc[:,i])\n",
    "    return data\n",
    "  except:\n",
    "    if data.dtype == 'object':\n",
    "      n=len(data)\n",
    "      data= label_encoder.fit_transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "EY=encod(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled,columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DTC_Scaler_NB.pkl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, \"DTC_Scaler_NB.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69302\n",
      "Precision: 0.77470\n",
      "Recall: 0.69302\n",
      "F1-score: 0.63977\n",
      "MCC: 0.42228\n",
      "Average Prediction Time: 63.3139 ms\n"
     ]
    }
   ],
   "source": [
    "# Attack detection + D_type\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled,EY, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = GaussianNB()\n",
    "\n",
    "\n",
    "\n",
    "# Define a function for evaluating a set of features using cross-validation\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, F1-score, and MCC\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")\n",
    "\n",
    "prediction_time = timeit.timeit(lambda: clf.predict(X_test), number=100) / 100\n",
    "print(f\"Average Prediction Time: {prediction_time * 1000:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'FIN_FC', 'TCPWS_Mean', 'RTT', 'PEntropy', 'FD', 'TCPWS_Sum', 'DACount', 'TCP_HD', 'TCPWS_Mode', 'FlowStd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance when deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('DeploymentDTC_new.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6923    0.5625    0.6207        32\n",
      "           1     0.5714    0.2182    0.3158        55\n",
      "           2     0.6160    0.9059    0.7333        85\n",
      "\n",
      "    accuracy                         0.6221       172\n",
      "   macro avg     0.6266    0.5622    0.5566       172\n",
      "weighted avg     0.6159    0.6221    0.5789       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.metrics import classification_report\n",
    "# (y_true, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')[source]\n",
    "print(classification_report(data['actual'],data['D_type'],digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62209\n",
      "Precision: 0.61594\n",
      "Recall: 0.62209\n",
      "F1-score: 0.57886\n",
      "MCC: 0.37772\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(data['actual'],data['D_type'])\n",
    "precision = precision_score(data['actual'],data['D_type'], average='weighted')\n",
    "recall = recall_score(data['actual'],data['D_type'], average='weighted')\n",
    "f1 = f1_score(data['actual'],data['D_type'], average='weighted')\n",
    "mcc = matthews_corrcoef(data['actual'],data['D_type'])\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18,  1, 13],\n",
       "       [ 8, 12, 35],\n",
       "       [ 0,  8, 77]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(data['actual'],data['D_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_3504\\3564978027.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(actual)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "actual\n",
       "2    46\n",
       "1    39\n",
       "0    19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('DeploymentResult_AD.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>S_MAC</th>\n",
       "      <th>label</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b2:a1:85:56:39:ce</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1e:4f:4f:91:15:eb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3e:2f:71:98:d3:80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6e:9c:57:09:b0:87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>9a:32:a5:5e:b4:f0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>1</td>\n",
       "      <td>e2:f8:a7:d9:d1:a7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>0</td>\n",
       "      <td>4e:58:fd:4d:10:26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>1</td>\n",
       "      <td>e2:f8:a7:d9:d1:a7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>0</td>\n",
       "      <td>4e:58:fd:4d:10:26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>1</td>\n",
       "      <td>e2:f8:a7:d9:d1:a7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2313 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sl              S_MAC  label  actual\n",
       "0      0  b2:a1:85:56:39:ce      1       1\n",
       "1      0  1e:4f:4f:91:15:eb      1       1\n",
       "2      1  3e:2f:71:98:d3:80      1       1\n",
       "3      2  6e:9c:57:09:b0:87      1       1\n",
       "4      3  9a:32:a5:5e:b4:f0      1       1\n",
       "...   ..                ...    ...     ...\n",
       "2308   1  e2:f8:a7:d9:d1:a7      1       1\n",
       "2309   0  4e:58:fd:4d:10:26      1       1\n",
       "2310   1  e2:f8:a7:d9:d1:a7      1       1\n",
       "2311   0  4e:58:fd:4d:10:26      1       1\n",
       "2312   1  e2:f8:a7:d9:d1:a7      1       1\n",
       "\n",
       "[2313 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4000    0.1040    0.1651       173\n",
      "           1     0.9317    0.9874    0.9587      2140\n",
      "\n",
      "    accuracy                         0.9213      2313\n",
      "   macro avg     0.6658    0.5457    0.5619      2313\n",
      "weighted avg     0.8919    0.9213    0.8994      2313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# (y_true, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')[source]\n",
    "print(classification_report(data['actual'],data['label'],digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92131\n",
      "Precision: 0.97020\n",
      "Recall: 0.92131\n",
      "F1-score: 0.94327\n",
      "MCC: 0.17414\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(data['label'], data['actual'])\n",
    "precision = precision_score(data['label'], data['actual'], average='weighted')\n",
    "recall = recall_score(data['label'], data['actual'], average='weighted')\n",
    "f1 = f1_score(data['label'], data['actual'], average='weighted')\n",
    "mcc = matthews_corrcoef(data['label'], data['actual'])\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  18,  155],\n",
       "       [  27, 2113]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(data['actual'],data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 - attack\n",
    "1 - normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('DeploymentResult_ADWDT.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=data[['label']]\n",
    "actual=data[['actual']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1429    0.0588    0.0833        85\n",
      "           1     0.8977    0.9590    0.9273       732\n",
      "\n",
      "    accuracy                         0.8654       817\n",
      "   macro avg     0.5203    0.5089    0.5053       817\n",
      "weighted avg     0.8192    0.8654    0.8395       817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# (y_true, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')[source]\n",
    "print(classification_report(actual,predicted,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86536\n",
      "Precision: 0.92045\n",
      "Recall: 0.86536\n",
      "F1-score: 0.89119\n",
      "MCC: 0.02690\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(predicted, actual)\n",
    "precision = precision_score(predicted, actual, average='weighted')\n",
    "recall = recall_score(predicted, actual, average='weighted')\n",
    "f1 = f1_score(predicted, actual, average='weighted')\n",
    "mcc = matthews_corrcoef(predicted, actual)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Recall: {recall:.5f}\")\n",
    "print(f\"F1-score: {f1:.5f}\")\n",
    "print(f\"MCC: {mcc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5,  80],\n",
       "       [ 30, 702]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(actual,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
